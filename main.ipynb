{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f42e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "839c2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5  # Batch size for training.\n",
    "epochs =700  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 100  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = \"seq2seq.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "438e2720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 140\n",
      "Number of unique input tokens: 75\n",
      "Number of unique output tokens: 62\n",
      "Max sequence length for inputs: 204\n",
      "Max sequence length for outputs: 68\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    \n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[1:141]:\n",
    "    input_text, target_text = line.split(\"\\t\")\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c1724840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cefa9222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "23/23 [==============================] - 14s 387ms/step - loss: 2.0229 - accuracy: 0.5797 - val_loss: 1.6251 - val_accuracy: 0.5940\n",
      "Epoch 2/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 1.5565 - accuracy: 0.6088 - val_loss: 1.6074 - val_accuracy: 0.5972\n",
      "Epoch 3/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 1.7026 - accuracy: 0.5982 - val_loss: 1.7409 - val_accuracy: 0.5919\n",
      "Epoch 4/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 1.5400 - accuracy: 0.6091 - val_loss: 1.5824 - val_accuracy: 0.6014\n",
      "Epoch 5/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 1.4655 - accuracy: 0.6162 - val_loss: 1.5817 - val_accuracy: 0.5872\n",
      "Epoch 6/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 1.4144 - accuracy: 0.6272 - val_loss: 1.4729 - val_accuracy: 0.6087\n",
      "Epoch 7/700\n",
      "23/23 [==============================] - 9s 377ms/step - loss: 1.3191 - accuracy: 0.6468 - val_loss: 2.2758 - val_accuracy: 0.6145\n",
      "Epoch 8/700\n",
      "23/23 [==============================] - 9s 372ms/step - loss: 1.3084 - accuracy: 0.6738 - val_loss: 1.3971 - val_accuracy: 0.6098\n",
      "Epoch 9/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 1.1764 - accuracy: 0.7017 - val_loss: 1.3352 - val_accuracy: 0.6124\n",
      "Epoch 10/700\n",
      "23/23 [==============================] - 10s 419ms/step - loss: 1.1686 - accuracy: 0.6872 - val_loss: 1.3152 - val_accuracy: 0.6392\n",
      "Epoch 11/700\n",
      "23/23 [==============================] - 9s 395ms/step - loss: 1.0474 - accuracy: 0.7260 - val_loss: 1.2543 - val_accuracy: 0.6303\n",
      "Epoch 12/700\n",
      "23/23 [==============================] - 9s 407ms/step - loss: 1.0355 - accuracy: 0.7332 - val_loss: 1.2063 - val_accuracy: 0.6486\n",
      "Epoch 13/700\n",
      "23/23 [==============================] - 9s 391ms/step - loss: 0.9551 - accuracy: 0.7487 - val_loss: 1.2280 - val_accuracy: 0.6534\n",
      "Epoch 14/700\n",
      "23/23 [==============================] - 10s 442ms/step - loss: 0.9309 - accuracy: 0.7558 - val_loss: 1.1466 - val_accuracy: 0.6812\n",
      "Epoch 15/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.8869 - accuracy: 0.7648 - val_loss: 1.0716 - val_accuracy: 0.7180\n",
      "Epoch 16/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.8463 - accuracy: 0.7764 - val_loss: 1.0414 - val_accuracy: 0.7274\n",
      "Epoch 17/700\n",
      "23/23 [==============================] - 9s 389ms/step - loss: 0.8119 - accuracy: 0.7855 - val_loss: 1.0394 - val_accuracy: 0.7185\n",
      "Epoch 18/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.7889 - accuracy: 0.7890 - val_loss: 0.9990 - val_accuracy: 0.7243\n",
      "Epoch 19/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.7473 - accuracy: 0.7998 - val_loss: 0.9966 - val_accuracy: 0.7206\n",
      "Epoch 20/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.7262 - accuracy: 0.8024 - val_loss: 1.0247 - val_accuracy: 0.7353\n",
      "Epoch 21/700\n",
      "23/23 [==============================] - 9s 372ms/step - loss: 0.7317 - accuracy: 0.8000 - val_loss: 0.8983 - val_accuracy: 0.7658\n",
      "Epoch 22/700\n",
      "23/23 [==============================] - 9s 409ms/step - loss: 0.6793 - accuracy: 0.8157 - val_loss: 0.8538 - val_accuracy: 0.7773\n",
      "Epoch 23/700\n",
      "23/23 [==============================] - 10s 425ms/step - loss: 0.6614 - accuracy: 0.8157 - val_loss: 0.9479 - val_accuracy: 0.7532\n",
      "Epoch 24/700\n",
      "23/23 [==============================] - 10s 417ms/step - loss: 0.6426 - accuracy: 0.8221 - val_loss: 0.8545 - val_accuracy: 0.7763\n",
      "Epoch 25/700\n",
      "23/23 [==============================] - 9s 389ms/step - loss: 0.6172 - accuracy: 0.8283 - val_loss: 0.8879 - val_accuracy: 0.7731\n",
      "Epoch 26/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.6044 - accuracy: 0.8292 - val_loss: 0.8609 - val_accuracy: 0.7700\n",
      "Epoch 27/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.5878 - accuracy: 0.8372 - val_loss: 0.8469 - val_accuracy: 0.7810\n",
      "Epoch 28/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.5692 - accuracy: 0.8427 - val_loss: 0.8583 - val_accuracy: 0.7736\n",
      "Epoch 29/700\n",
      "23/23 [==============================] - 9s 401ms/step - loss: 0.5521 - accuracy: 0.8439 - val_loss: 1.0155 - val_accuracy: 0.7384\n",
      "Epoch 30/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.5470 - accuracy: 0.8470 - val_loss: 0.8349 - val_accuracy: 0.7826\n",
      "Epoch 31/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.5268 - accuracy: 0.8507 - val_loss: 0.8490 - val_accuracy: 0.7794\n",
      "Epoch 32/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.5138 - accuracy: 0.8566 - val_loss: 0.8778 - val_accuracy: 0.7626\n",
      "Epoch 33/700\n",
      "23/23 [==============================] - 9s 382ms/step - loss: 0.4977 - accuracy: 0.8615 - val_loss: 0.8431 - val_accuracy: 0.7852\n",
      "Epoch 34/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.4865 - accuracy: 0.8603 - val_loss: 0.8489 - val_accuracy: 0.7784\n",
      "Epoch 35/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.4716 - accuracy: 0.8659 - val_loss: 0.8436 - val_accuracy: 0.7789\n",
      "Epoch 36/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.4654 - accuracy: 0.8675 - val_loss: 0.8518 - val_accuracy: 0.7873\n",
      "Epoch 37/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.4474 - accuracy: 0.8753 - val_loss: 0.8830 - val_accuracy: 0.7778\n",
      "Epoch 38/700\n",
      "23/23 [==============================] - 9s 396ms/step - loss: 0.4317 - accuracy: 0.8789 - val_loss: 0.9013 - val_accuracy: 0.7668\n",
      "Epoch 39/700\n",
      "23/23 [==============================] - 9s 374ms/step - loss: 0.4259 - accuracy: 0.8795 - val_loss: 0.9137 - val_accuracy: 0.7595\n",
      "Epoch 40/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.4141 - accuracy: 0.8827 - val_loss: 0.8641 - val_accuracy: 0.7705\n",
      "Epoch 41/700\n",
      "23/23 [==============================] - 9s 370ms/step - loss: 0.4044 - accuracy: 0.8847 - val_loss: 0.8980 - val_accuracy: 0.7689\n",
      "Epoch 42/700\n",
      "23/23 [==============================] - 8s 369ms/step - loss: 0.3848 - accuracy: 0.8892 - val_loss: 0.8641 - val_accuracy: 0.7836\n",
      "Epoch 43/700\n",
      "23/23 [==============================] - 9s 377ms/step - loss: 0.3770 - accuracy: 0.8948 - val_loss: 0.8769 - val_accuracy: 0.7757\n",
      "Epoch 44/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.3651 - accuracy: 0.8944 - val_loss: 0.9092 - val_accuracy: 0.7673\n",
      "Epoch 45/700\n",
      "23/23 [==============================] - 9s 374ms/step - loss: 0.3487 - accuracy: 0.9013 - val_loss: 0.9380 - val_accuracy: 0.7616\n",
      "Epoch 46/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.3446 - accuracy: 0.9013 - val_loss: 0.8913 - val_accuracy: 0.7684\n",
      "Epoch 47/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.3295 - accuracy: 0.9073 - val_loss: 0.9171 - val_accuracy: 0.7689\n",
      "Epoch 48/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.3211 - accuracy: 0.9085 - val_loss: 0.9878 - val_accuracy: 0.7558\n",
      "Epoch 49/700\n",
      "23/23 [==============================] - 9s 399ms/step - loss: 0.3124 - accuracy: 0.9106 - val_loss: 0.9396 - val_accuracy: 0.7668\n",
      "Epoch 50/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.3018 - accuracy: 0.9141 - val_loss: 0.9796 - val_accuracy: 0.7516\n",
      "Epoch 51/700\n",
      "23/23 [==============================] - 9s 394ms/step - loss: 0.2863 - accuracy: 0.9213 - val_loss: 0.9959 - val_accuracy: 0.7516\n",
      "Epoch 52/700\n",
      "23/23 [==============================] - 10s 446ms/step - loss: 0.2788 - accuracy: 0.9204 - val_loss: 1.0061 - val_accuracy: 0.7474\n",
      "Epoch 53/700\n",
      "23/23 [==============================] - 9s 401ms/step - loss: 0.2730 - accuracy: 0.9233 - val_loss: 0.9677 - val_accuracy: 0.7742\n",
      "Epoch 54/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.2601 - accuracy: 0.9279 - val_loss: 0.9877 - val_accuracy: 0.7605\n",
      "Epoch 55/700\n",
      "23/23 [==============================] - 9s 380ms/step - loss: 0.2478 - accuracy: 0.9305 - val_loss: 0.9995 - val_accuracy: 0.7542\n",
      "Epoch 56/700\n",
      "23/23 [==============================] - 9s 372ms/step - loss: 0.2436 - accuracy: 0.9329 - val_loss: 1.0303 - val_accuracy: 0.7542\n",
      "Epoch 57/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.2348 - accuracy: 0.9351 - val_loss: 1.0378 - val_accuracy: 0.7568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/700\n",
      "23/23 [==============================] - 9s 395ms/step - loss: 0.2274 - accuracy: 0.9380 - val_loss: 1.0284 - val_accuracy: 0.7537\n",
      "Epoch 59/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.2170 - accuracy: 0.9407 - val_loss: 1.0592 - val_accuracy: 0.7500\n",
      "Epoch 60/700\n",
      "23/23 [==============================] - 9s 371ms/step - loss: 0.2097 - accuracy: 0.9437 - val_loss: 1.0608 - val_accuracy: 0.7616\n",
      "Epoch 61/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.2065 - accuracy: 0.9447 - val_loss: 1.1020 - val_accuracy: 0.7500\n",
      "Epoch 62/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.1989 - accuracy: 0.9463 - val_loss: 1.0531 - val_accuracy: 0.7642\n",
      "Epoch 63/700\n",
      "23/23 [==============================] - 9s 376ms/step - loss: 0.1909 - accuracy: 0.9484 - val_loss: 1.1543 - val_accuracy: 0.7463\n",
      "Epoch 64/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.1857 - accuracy: 0.9497 - val_loss: 1.1371 - val_accuracy: 0.7521\n",
      "Epoch 65/700\n",
      "23/23 [==============================] - 9s 374ms/step - loss: 0.1790 - accuracy: 0.9513 - val_loss: 1.1214 - val_accuracy: 0.7568\n",
      "Epoch 66/700\n",
      "23/23 [==============================] - 9s 395ms/step - loss: 0.1742 - accuracy: 0.9533 - val_loss: 1.0930 - val_accuracy: 0.7631\n",
      "Epoch 67/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.1691 - accuracy: 0.9548 - val_loss: 1.1796 - val_accuracy: 0.7479\n",
      "Epoch 68/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.1711 - accuracy: 0.9546 - val_loss: 1.1041 - val_accuracy: 0.7595\n",
      "Epoch 69/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.1581 - accuracy: 0.9565 - val_loss: 1.1983 - val_accuracy: 0.7416\n",
      "Epoch 70/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.1555 - accuracy: 0.9580 - val_loss: 1.1821 - val_accuracy: 0.7463\n",
      "Epoch 71/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.1515 - accuracy: 0.9588 - val_loss: 1.1296 - val_accuracy: 0.7579\n",
      "Epoch 72/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.1457 - accuracy: 0.9609 - val_loss: 1.1519 - val_accuracy: 0.7547\n",
      "Epoch 73/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.1432 - accuracy: 0.9615 - val_loss: 1.1684 - val_accuracy: 0.7526\n",
      "Epoch 74/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.1387 - accuracy: 0.9613 - val_loss: 1.1806 - val_accuracy: 0.7516\n",
      "Epoch 75/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.1402 - accuracy: 0.9621 - val_loss: 1.1868 - val_accuracy: 0.7610\n",
      "Epoch 76/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.1360 - accuracy: 0.9639 - val_loss: 1.2685 - val_accuracy: 0.7321\n",
      "Epoch 77/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.1292 - accuracy: 0.9661 - val_loss: 1.2105 - val_accuracy: 0.7521\n",
      "Epoch 78/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.1258 - accuracy: 0.9647 - val_loss: 1.2290 - val_accuracy: 0.7511\n",
      "Epoch 79/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.1271 - accuracy: 0.9645 - val_loss: 1.2078 - val_accuracy: 0.7547\n",
      "Epoch 80/700\n",
      "23/23 [==============================] - 9s 410ms/step - loss: 0.1220 - accuracy: 0.9657 - val_loss: 1.2448 - val_accuracy: 0.7505\n",
      "Epoch 81/700\n",
      "23/23 [==============================] - 9s 382ms/step - loss: 0.1189 - accuracy: 0.9670 - val_loss: 1.2839 - val_accuracy: 0.7516\n",
      "Epoch 82/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.1241 - accuracy: 0.9643 - val_loss: 1.2804 - val_accuracy: 0.7526\n",
      "Epoch 83/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.1180 - accuracy: 0.9672 - val_loss: 1.2595 - val_accuracy: 0.7537\n",
      "Epoch 84/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.1149 - accuracy: 0.9666 - val_loss: 1.3222 - val_accuracy: 0.7453\n",
      "Epoch 85/700\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.1159 - accuracy: 0.9665 - val_loss: 1.2659 - val_accuracy: 0.7574\n",
      "Epoch 86/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.1101 - accuracy: 0.9678 - val_loss: 1.2785 - val_accuracy: 0.7526\n",
      "Epoch 87/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.1083 - accuracy: 0.9689 - val_loss: 1.3063 - val_accuracy: 0.7553\n",
      "Epoch 88/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.1095 - accuracy: 0.9681 - val_loss: 1.2839 - val_accuracy: 0.7595\n",
      "Epoch 89/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.1061 - accuracy: 0.9684 - val_loss: 1.2942 - val_accuracy: 0.7553\n",
      "Epoch 90/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.1059 - accuracy: 0.9681 - val_loss: 1.2946 - val_accuracy: 0.7574\n",
      "Epoch 91/700\n",
      "23/23 [==============================] - 8s 338ms/step - loss: 0.1056 - accuracy: 0.9681 - val_loss: 1.2928 - val_accuracy: 0.7621\n",
      "Epoch 92/700\n",
      "23/23 [==============================] - 8s 337ms/step - loss: 0.1010 - accuracy: 0.9697 - val_loss: 1.3214 - val_accuracy: 0.7495\n",
      "Epoch 93/700\n",
      "23/23 [==============================] - 8s 336ms/step - loss: 0.1016 - accuracy: 0.9695 - val_loss: 1.3569 - val_accuracy: 0.7489\n",
      "Epoch 94/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.1006 - accuracy: 0.9695 - val_loss: 1.3699 - val_accuracy: 0.7505\n",
      "Epoch 95/700\n",
      "23/23 [==============================] - 9s 390ms/step - loss: 0.0984 - accuracy: 0.9707 - val_loss: 1.3907 - val_accuracy: 0.7474\n",
      "Epoch 96/700\n",
      "23/23 [==============================] - 9s 409ms/step - loss: 0.0986 - accuracy: 0.9695 - val_loss: 1.3373 - val_accuracy: 0.7610\n",
      "Epoch 97/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0965 - accuracy: 0.9703 - val_loss: 1.3482 - val_accuracy: 0.7532\n",
      "Epoch 98/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0964 - accuracy: 0.9699 - val_loss: 1.3489 - val_accuracy: 0.7568\n",
      "Epoch 99/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0982 - accuracy: 0.9688 - val_loss: 1.3905 - val_accuracy: 0.7479\n",
      "Epoch 100/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0955 - accuracy: 0.9705 - val_loss: 1.4061 - val_accuracy: 0.7495\n",
      "Epoch 101/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0936 - accuracy: 0.9707 - val_loss: 1.3491 - val_accuracy: 0.7474\n",
      "Epoch 102/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0940 - accuracy: 0.9709 - val_loss: 1.3368 - val_accuracy: 0.7526\n",
      "Epoch 103/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0987 - accuracy: 0.9697 - val_loss: 1.3882 - val_accuracy: 0.7484\n",
      "Epoch 104/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0923 - accuracy: 0.9710 - val_loss: 1.3757 - val_accuracy: 0.7458\n",
      "Epoch 105/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0919 - accuracy: 0.9703 - val_loss: 1.3869 - val_accuracy: 0.7526\n",
      "Epoch 106/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0932 - accuracy: 0.9693 - val_loss: 1.3916 - val_accuracy: 0.7553\n",
      "Epoch 107/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0916 - accuracy: 0.9693 - val_loss: 1.4090 - val_accuracy: 0.7400\n",
      "Epoch 108/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0908 - accuracy: 0.9718 - val_loss: 1.3817 - val_accuracy: 0.7495\n",
      "Epoch 109/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0902 - accuracy: 0.9716 - val_loss: 1.4280 - val_accuracy: 0.7442\n",
      "Epoch 110/700\n",
      "23/23 [==============================] - 9s 395ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 1.4358 - val_accuracy: 0.7474\n",
      "Epoch 111/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0896 - accuracy: 0.9719 - val_loss: 1.4266 - val_accuracy: 0.7468\n",
      "Epoch 112/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0938 - accuracy: 0.9699 - val_loss: 1.3875 - val_accuracy: 0.7537\n",
      "Epoch 113/700\n",
      "23/23 [==============================] - 9s 391ms/step - loss: 0.0884 - accuracy: 0.9715 - val_loss: 1.4400 - val_accuracy: 0.7474\n",
      "Epoch 114/700\n",
      "23/23 [==============================] - 8s 370ms/step - loss: 0.0893 - accuracy: 0.9705 - val_loss: 1.4702 - val_accuracy: 0.7379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 0.0881 - accuracy: 0.9711 - val_loss: 1.4514 - val_accuracy: 0.7542\n",
      "Epoch 116/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0872 - accuracy: 0.9707 - val_loss: 1.4153 - val_accuracy: 0.7521\n",
      "Epoch 117/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0867 - accuracy: 0.9710 - val_loss: 1.4268 - val_accuracy: 0.7547\n",
      "Epoch 118/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0878 - accuracy: 0.9710 - val_loss: 1.4420 - val_accuracy: 0.7505\n",
      "Epoch 119/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 1.4488 - val_accuracy: 0.7474\n",
      "Epoch 120/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0861 - accuracy: 0.9718 - val_loss: 1.4355 - val_accuracy: 0.7521\n",
      "Epoch 121/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0865 - accuracy: 0.9703 - val_loss: 1.4561 - val_accuracy: 0.7537\n",
      "Epoch 122/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0861 - accuracy: 0.9718 - val_loss: 1.4691 - val_accuracy: 0.7511\n",
      "Epoch 123/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0848 - accuracy: 0.9712 - val_loss: 1.5078 - val_accuracy: 0.7468\n",
      "Epoch 124/700\n",
      "23/23 [==============================] - 9s 397ms/step - loss: 0.0837 - accuracy: 0.9715 - val_loss: 1.4915 - val_accuracy: 0.7416\n",
      "Epoch 125/700\n",
      "23/23 [==============================] - 9s 392ms/step - loss: 0.0847 - accuracy: 0.9719 - val_loss: 1.4911 - val_accuracy: 0.7474\n",
      "Epoch 126/700\n",
      "23/23 [==============================] - 9s 377ms/step - loss: 0.0854 - accuracy: 0.9714 - val_loss: 1.5082 - val_accuracy: 0.7453\n",
      "Epoch 127/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0846 - accuracy: 0.9722 - val_loss: 1.5170 - val_accuracy: 0.7500\n",
      "Epoch 128/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0842 - accuracy: 0.9716 - val_loss: 1.4838 - val_accuracy: 0.7479\n",
      "Epoch 129/700\n",
      "23/23 [==============================] - 9s 385ms/step - loss: 0.0837 - accuracy: 0.9715 - val_loss: 1.5091 - val_accuracy: 0.7511\n",
      "Epoch 130/700\n",
      "23/23 [==============================] - 8s 335ms/step - loss: 0.0841 - accuracy: 0.9706 - val_loss: 1.5288 - val_accuracy: 0.7453\n",
      "Epoch 131/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0836 - accuracy: 0.9715 - val_loss: 1.4631 - val_accuracy: 0.7563\n",
      "Epoch 132/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0833 - accuracy: 0.9716 - val_loss: 1.5210 - val_accuracy: 0.7495\n",
      "Epoch 133/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0835 - accuracy: 0.9709 - val_loss: 1.5242 - val_accuracy: 0.7437\n",
      "Epoch 134/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0829 - accuracy: 0.9722 - val_loss: 1.5156 - val_accuracy: 0.7484\n",
      "Epoch 135/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0829 - accuracy: 0.9703 - val_loss: 1.5132 - val_accuracy: 0.7553\n",
      "Epoch 136/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0827 - accuracy: 0.9718 - val_loss: 1.5393 - val_accuracy: 0.7489\n",
      "Epoch 137/700\n",
      "23/23 [==============================] - 9s 382ms/step - loss: 0.0819 - accuracy: 0.9709 - val_loss: 1.5307 - val_accuracy: 0.7458\n",
      "Epoch 138/700\n",
      "23/23 [==============================] - 9s 393ms/step - loss: 0.0808 - accuracy: 0.9726 - val_loss: 1.5524 - val_accuracy: 0.7516\n",
      "Epoch 139/700\n",
      "23/23 [==============================] - 10s 420ms/step - loss: 0.0822 - accuracy: 0.9730 - val_loss: 1.5326 - val_accuracy: 0.7453\n",
      "Epoch 140/700\n",
      "23/23 [==============================] - 9s 392ms/step - loss: 0.0819 - accuracy: 0.9718 - val_loss: 1.5019 - val_accuracy: 0.7432\n",
      "Epoch 141/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0819 - accuracy: 0.9727 - val_loss: 1.5390 - val_accuracy: 0.7447\n",
      "Epoch 142/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0813 - accuracy: 0.9720 - val_loss: 1.5433 - val_accuracy: 0.7468\n",
      "Epoch 143/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0814 - accuracy: 0.9715 - val_loss: 1.5508 - val_accuracy: 0.7421\n",
      "Epoch 144/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0814 - accuracy: 0.9719 - val_loss: 1.5725 - val_accuracy: 0.7405\n",
      "Epoch 145/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0809 - accuracy: 0.9724 - val_loss: 1.5789 - val_accuracy: 0.7484\n",
      "Epoch 146/700\n",
      "23/23 [==============================] - 8s 338ms/step - loss: 0.0811 - accuracy: 0.9711 - val_loss: 1.5483 - val_accuracy: 0.7468\n",
      "Epoch 147/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0804 - accuracy: 0.9718 - val_loss: 1.5705 - val_accuracy: 0.7511\n",
      "Epoch 148/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0805 - accuracy: 0.9715 - val_loss: 1.5685 - val_accuracy: 0.7489\n",
      "Epoch 149/700\n",
      "23/23 [==============================] - 9s 373ms/step - loss: 0.0795 - accuracy: 0.9723 - val_loss: 1.5677 - val_accuracy: 0.7416\n",
      "Epoch 150/700\n",
      "23/23 [==============================] - 9s 374ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 1.5778 - val_accuracy: 0.7500\n",
      "Epoch 151/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0795 - accuracy: 0.9720 - val_loss: 1.5975 - val_accuracy: 0.7463\n",
      "Epoch 152/700\n",
      "23/23 [==============================] - 9s 370ms/step - loss: 0.0802 - accuracy: 0.9712 - val_loss: 1.5712 - val_accuracy: 0.7437\n",
      "Epoch 153/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0803 - accuracy: 0.9720 - val_loss: 1.5625 - val_accuracy: 0.7463\n",
      "Epoch 154/700\n",
      "23/23 [==============================] - 10s 418ms/step - loss: 0.0797 - accuracy: 0.9714 - val_loss: 1.5577 - val_accuracy: 0.7505\n",
      "Epoch 155/700\n",
      "23/23 [==============================] - 9s 376ms/step - loss: 0.0796 - accuracy: 0.9728 - val_loss: 1.5746 - val_accuracy: 0.7521\n",
      "Epoch 156/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0790 - accuracy: 0.9727 - val_loss: 1.5910 - val_accuracy: 0.7421\n",
      "Epoch 157/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0790 - accuracy: 0.9720 - val_loss: 1.5978 - val_accuracy: 0.7547\n",
      "Epoch 158/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0792 - accuracy: 0.9719 - val_loss: 1.5965 - val_accuracy: 0.7447\n",
      "Epoch 159/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0792 - accuracy: 0.9726 - val_loss: 1.5947 - val_accuracy: 0.7505\n",
      "Epoch 160/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0789 - accuracy: 0.9728 - val_loss: 1.6083 - val_accuracy: 0.7453\n",
      "Epoch 161/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0787 - accuracy: 0.9723 - val_loss: 1.6108 - val_accuracy: 0.7500\n",
      "Epoch 162/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0787 - accuracy: 0.9727 - val_loss: 1.6158 - val_accuracy: 0.7468\n",
      "Epoch 163/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0788 - accuracy: 0.9726 - val_loss: 1.6131 - val_accuracy: 0.7500\n",
      "Epoch 164/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0784 - accuracy: 0.9719 - val_loss: 1.6109 - val_accuracy: 0.7426\n",
      "Epoch 165/700\n",
      "23/23 [==============================] - 9s 373ms/step - loss: 0.0782 - accuracy: 0.9737 - val_loss: 1.6370 - val_accuracy: 0.7390\n",
      "Epoch 166/700\n",
      "23/23 [==============================] - 9s 370ms/step - loss: 0.0781 - accuracy: 0.9730 - val_loss: 1.6382 - val_accuracy: 0.7442\n",
      "Epoch 167/700\n",
      "23/23 [==============================] - 9s 395ms/step - loss: 0.0782 - accuracy: 0.9722 - val_loss: 1.6285 - val_accuracy: 0.7500\n",
      "Epoch 168/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0785 - accuracy: 0.9722 - val_loss: 1.6483 - val_accuracy: 0.7426\n",
      "Epoch 169/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0778 - accuracy: 0.9730 - val_loss: 1.6199 - val_accuracy: 0.7348\n",
      "Epoch 170/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.1099 - accuracy: 0.9644 - val_loss: 1.5718 - val_accuracy: 0.7442\n",
      "Epoch 171/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0841 - accuracy: 0.9718 - val_loss: 1.6234 - val_accuracy: 0.7453\n",
      "Epoch 172/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0791 - accuracy: 0.9728 - val_loss: 1.5914 - val_accuracy: 0.7411\n",
      "Epoch 173/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0768 - accuracy: 0.9727 - val_loss: 1.5946 - val_accuracy: 0.7390\n",
      "Epoch 174/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0786 - accuracy: 0.9720 - val_loss: 1.5982 - val_accuracy: 0.7521\n",
      "Epoch 175/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0865 - accuracy: 0.9694 - val_loss: 1.5739 - val_accuracy: 0.7374\n",
      "Epoch 176/700\n",
      "23/23 [==============================] - 8s 339ms/step - loss: 0.0839 - accuracy: 0.9710 - val_loss: 1.5655 - val_accuracy: 0.7416\n",
      "Epoch 177/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0787 - accuracy: 0.9718 - val_loss: 1.6473 - val_accuracy: 0.7337\n",
      "Epoch 178/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0788 - accuracy: 0.9731 - val_loss: 1.5474 - val_accuracy: 0.7405\n",
      "Epoch 179/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0808 - accuracy: 0.9712 - val_loss: 1.5978 - val_accuracy: 0.7411\n",
      "Epoch 180/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 1.6172 - val_accuracy: 0.7426\n",
      "Epoch 181/700\n",
      "23/23 [==============================] - 9s 374ms/step - loss: 0.0754 - accuracy: 0.9733 - val_loss: 1.6129 - val_accuracy: 0.7379\n",
      "Epoch 182/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0766 - accuracy: 0.9726 - val_loss: 1.6605 - val_accuracy: 0.7353\n",
      "Epoch 183/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0773 - accuracy: 0.9723 - val_loss: 1.6273 - val_accuracy: 0.7416\n",
      "Epoch 184/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0777 - accuracy: 0.9723 - val_loss: 1.6720 - val_accuracy: 0.7342\n",
      "Epoch 185/700\n",
      "23/23 [==============================] - 9s 386ms/step - loss: 0.0768 - accuracy: 0.9736 - val_loss: 1.6655 - val_accuracy: 0.7337\n",
      "Epoch 186/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0772 - accuracy: 0.9727 - val_loss: 1.6671 - val_accuracy: 0.7353\n",
      "Epoch 187/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0777 - accuracy: 0.9720 - val_loss: 1.6909 - val_accuracy: 0.7311\n",
      "Epoch 188/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0767 - accuracy: 0.9716 - val_loss: 1.6365 - val_accuracy: 0.7453\n",
      "Epoch 189/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0760 - accuracy: 0.9722 - val_loss: 1.6661 - val_accuracy: 0.7390\n",
      "Epoch 190/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 0.0767 - accuracy: 0.9719 - val_loss: 1.6513 - val_accuracy: 0.7395\n",
      "Epoch 191/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0865 - accuracy: 0.9698 - val_loss: 1.6177 - val_accuracy: 0.7426\n",
      "Epoch 192/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0766 - accuracy: 0.9722 - val_loss: 1.6464 - val_accuracy: 0.7426\n",
      "Epoch 193/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0765 - accuracy: 0.9724 - val_loss: 1.6383 - val_accuracy: 0.7411\n",
      "Epoch 194/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0758 - accuracy: 0.9732 - val_loss: 1.6700 - val_accuracy: 0.7369\n",
      "Epoch 195/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 0.0761 - accuracy: 0.9732 - val_loss: 1.7276 - val_accuracy: 0.7337\n",
      "Epoch 196/700\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0819 - accuracy: 0.9730 - val_loss: 1.6114 - val_accuracy: 0.7411\n",
      "Epoch 197/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0759 - accuracy: 0.9727 - val_loss: 1.6397 - val_accuracy: 0.7416\n",
      "Epoch 198/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0747 - accuracy: 0.9733 - val_loss: 1.6575 - val_accuracy: 0.7316\n",
      "Epoch 199/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0757 - accuracy: 0.9731 - val_loss: 1.6791 - val_accuracy: 0.7379\n",
      "Epoch 200/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0751 - accuracy: 0.9723 - val_loss: 1.7073 - val_accuracy: 0.7311\n",
      "Epoch 201/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0771 - accuracy: 0.9733 - val_loss: 1.6707 - val_accuracy: 0.7390\n",
      "Epoch 202/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0798 - accuracy: 0.9719 - val_loss: 1.6295 - val_accuracy: 0.7405\n",
      "Epoch 203/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0753 - accuracy: 0.9728 - val_loss: 1.6339 - val_accuracy: 0.7474\n",
      "Epoch 204/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0798 - accuracy: 0.9720 - val_loss: 1.6301 - val_accuracy: 0.7379\n",
      "Epoch 205/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0744 - accuracy: 0.9736 - val_loss: 1.6439 - val_accuracy: 0.7442\n",
      "Epoch 206/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0759 - accuracy: 0.9720 - val_loss: 1.6427 - val_accuracy: 0.7426\n",
      "Epoch 207/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0755 - accuracy: 0.9736 - val_loss: 1.6870 - val_accuracy: 0.7432\n",
      "Epoch 208/700\n",
      "23/23 [==============================] - 8s 370ms/step - loss: 0.0745 - accuracy: 0.9730 - val_loss: 1.6578 - val_accuracy: 0.7442\n",
      "Epoch 209/700\n",
      "23/23 [==============================] - 8s 329ms/step - loss: 0.0764 - accuracy: 0.9724 - val_loss: 1.6549 - val_accuracy: 0.7516\n",
      "Epoch 210/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0768 - accuracy: 0.9732 - val_loss: 1.6590 - val_accuracy: 0.7405\n",
      "Epoch 211/700\n",
      "23/23 [==============================] - 9s 396ms/step - loss: 0.0752 - accuracy: 0.9726 - val_loss: 1.6616 - val_accuracy: 0.7484\n",
      "Epoch 212/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0750 - accuracy: 0.9722 - val_loss: 1.6714 - val_accuracy: 0.7432\n",
      "Epoch 213/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0750 - accuracy: 0.9730 - val_loss: 1.6797 - val_accuracy: 0.7395\n",
      "Epoch 214/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0745 - accuracy: 0.9726 - val_loss: 1.6512 - val_accuracy: 0.7474\n",
      "Epoch 215/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0748 - accuracy: 0.9730 - val_loss: 1.7000 - val_accuracy: 0.7384\n",
      "Epoch 216/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0811 - accuracy: 0.9711 - val_loss: 1.6759 - val_accuracy: 0.7421\n",
      "Epoch 217/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0782 - accuracy: 0.9727 - val_loss: 1.7190 - val_accuracy: 0.7400\n",
      "Epoch 218/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0764 - accuracy: 0.9730 - val_loss: 1.5903 - val_accuracy: 0.7479\n",
      "Epoch 219/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0734 - accuracy: 0.9732 - val_loss: 1.6057 - val_accuracy: 0.7437\n",
      "Epoch 220/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0741 - accuracy: 0.9726 - val_loss: 1.6237 - val_accuracy: 0.7447\n",
      "Epoch 221/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0744 - accuracy: 0.9733 - val_loss: 1.6300 - val_accuracy: 0.7432\n",
      "Epoch 222/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0749 - accuracy: 0.9732 - val_loss: 1.6087 - val_accuracy: 0.7463\n",
      "Epoch 223/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0752 - accuracy: 0.9728 - val_loss: 1.6257 - val_accuracy: 0.7437\n",
      "Epoch 224/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0743 - accuracy: 0.9730 - val_loss: 1.6131 - val_accuracy: 0.7474\n",
      "Epoch 225/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0749 - accuracy: 0.9727 - val_loss: 1.7121 - val_accuracy: 0.7432\n",
      "Epoch 226/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0833 - accuracy: 0.9722 - val_loss: 1.6018 - val_accuracy: 0.7505\n",
      "Epoch 227/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0732 - accuracy: 0.9732 - val_loss: 1.6275 - val_accuracy: 0.7468\n",
      "Epoch 228/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0784 - accuracy: 0.9716 - val_loss: 1.6449 - val_accuracy: 0.7426\n",
      "Epoch 229/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0736 - accuracy: 0.9737 - val_loss: 1.6392 - val_accuracy: 0.7511\n",
      "Epoch 230/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0744 - accuracy: 0.9735 - val_loss: 1.6466 - val_accuracy: 0.7453\n",
      "Epoch 231/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0740 - accuracy: 0.9736 - val_loss: 1.6912 - val_accuracy: 0.7437\n",
      "Epoch 232/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.1295 - accuracy: 0.9602 - val_loss: 1.5729 - val_accuracy: 0.7432\n",
      "Epoch 233/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.1011 - accuracy: 0.9664 - val_loss: 1.6466 - val_accuracy: 0.7437\n",
      "Epoch 234/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0768 - accuracy: 0.9732 - val_loss: 1.6381 - val_accuracy: 0.7348\n",
      "Epoch 235/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0754 - accuracy: 0.9735 - val_loss: 1.7087 - val_accuracy: 0.7285\n",
      "Epoch 236/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0770 - accuracy: 0.9733 - val_loss: 1.6509 - val_accuracy: 0.7479\n",
      "Epoch 237/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0811 - accuracy: 0.9712 - val_loss: 1.5687 - val_accuracy: 0.7416\n",
      "Epoch 238/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0885 - accuracy: 0.9691 - val_loss: 1.5573 - val_accuracy: 0.7458\n",
      "Epoch 239/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0794 - accuracy: 0.9727 - val_loss: 1.5783 - val_accuracy: 0.7432\n",
      "Epoch 240/700\n",
      "23/23 [==============================] - 8s 337ms/step - loss: 0.0934 - accuracy: 0.9681 - val_loss: 1.5246 - val_accuracy: 0.7521\n",
      "Epoch 241/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0783 - accuracy: 0.9732 - val_loss: 1.5652 - val_accuracy: 0.7458\n",
      "Epoch 242/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0734 - accuracy: 0.9735 - val_loss: 1.5654 - val_accuracy: 0.7495\n",
      "Epoch 243/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0730 - accuracy: 0.9737 - val_loss: 1.5951 - val_accuracy: 0.7484\n",
      "Epoch 244/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0730 - accuracy: 0.9741 - val_loss: 1.5365 - val_accuracy: 0.7553\n",
      "Epoch 245/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0733 - accuracy: 0.9736 - val_loss: 1.5845 - val_accuracy: 0.7526\n",
      "Epoch 246/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0737 - accuracy: 0.9736 - val_loss: 1.6098 - val_accuracy: 0.7505\n",
      "Epoch 247/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0762 - accuracy: 0.9728 - val_loss: 1.6233 - val_accuracy: 0.7532\n",
      "Epoch 248/700\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0755 - accuracy: 0.9732 - val_loss: 1.6217 - val_accuracy: 0.7521\n",
      "Epoch 249/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0742 - accuracy: 0.9731 - val_loss: 1.6034 - val_accuracy: 0.7542\n",
      "Epoch 250/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0802 - accuracy: 0.9706 - val_loss: 1.5109 - val_accuracy: 0.7700\n",
      "Epoch 251/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0712 - accuracy: 0.9737 - val_loss: 1.5751 - val_accuracy: 0.7642\n",
      "Epoch 252/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0709 - accuracy: 0.9745 - val_loss: 1.5619 - val_accuracy: 0.7631\n",
      "Epoch 253/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0725 - accuracy: 0.9745 - val_loss: 1.6090 - val_accuracy: 0.7616\n",
      "Epoch 254/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0735 - accuracy: 0.9730 - val_loss: 1.5863 - val_accuracy: 0.7673\n",
      "Epoch 255/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0731 - accuracy: 0.9735 - val_loss: 1.6179 - val_accuracy: 0.7663\n",
      "Epoch 256/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0728 - accuracy: 0.9741 - val_loss: 1.6330 - val_accuracy: 0.7547\n",
      "Epoch 257/700\n",
      "23/23 [==============================] - 9s 387ms/step - loss: 0.0723 - accuracy: 0.9737 - val_loss: 1.6244 - val_accuracy: 0.7600\n",
      "Epoch 258/700\n",
      "23/23 [==============================] - 9s 408ms/step - loss: 0.0722 - accuracy: 0.9740 - val_loss: 1.6191 - val_accuracy: 0.7626\n",
      "Epoch 259/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0732 - accuracy: 0.9736 - val_loss: 1.7114 - val_accuracy: 0.7511\n",
      "Epoch 260/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0720 - accuracy: 0.9749 - val_loss: 1.6223 - val_accuracy: 0.7647\n",
      "Epoch 261/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0711 - accuracy: 0.9737 - val_loss: 1.6267 - val_accuracy: 0.7579\n",
      "Epoch 262/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0712 - accuracy: 0.9747 - val_loss: 1.6558 - val_accuracy: 0.7547\n",
      "Epoch 263/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0714 - accuracy: 0.9752 - val_loss: 1.6507 - val_accuracy: 0.7553\n",
      "Epoch 264/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0710 - accuracy: 0.9735 - val_loss: 1.6452 - val_accuracy: 0.7579\n",
      "Epoch 265/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0814 - accuracy: 0.9710 - val_loss: 1.6727 - val_accuracy: 0.7442\n",
      "Epoch 266/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0704 - accuracy: 0.9747 - val_loss: 1.6907 - val_accuracy: 0.7453\n",
      "Epoch 267/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0696 - accuracy: 0.9756 - val_loss: 1.7152 - val_accuracy: 0.7479\n",
      "Epoch 268/700\n",
      "23/23 [==============================] - 9s 401ms/step - loss: 0.0713 - accuracy: 0.9748 - val_loss: 1.6956 - val_accuracy: 0.7547\n",
      "Epoch 269/700\n",
      "23/23 [==============================] - 9s 389ms/step - loss: 0.0699 - accuracy: 0.9753 - val_loss: 1.7294 - val_accuracy: 0.7453\n",
      "Epoch 270/700\n",
      "23/23 [==============================] - 9s 389ms/step - loss: 0.0704 - accuracy: 0.9757 - val_loss: 1.7038 - val_accuracy: 0.7458\n",
      "Epoch 271/700\n",
      "23/23 [==============================] - 9s 381ms/step - loss: 0.0704 - accuracy: 0.9740 - val_loss: 1.7438 - val_accuracy: 0.7542\n",
      "Epoch 272/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 0.0692 - accuracy: 0.9751 - val_loss: 1.7667 - val_accuracy: 0.7463\n",
      "Epoch 273/700\n",
      "23/23 [==============================] - 9s 397ms/step - loss: 0.0831 - accuracy: 0.9719 - val_loss: 1.6599 - val_accuracy: 0.7474\n",
      "Epoch 274/700\n",
      "23/23 [==============================] - 9s 409ms/step - loss: 0.0666 - accuracy: 0.9761 - val_loss: 1.6552 - val_accuracy: 0.7484\n",
      "Epoch 275/700\n",
      "23/23 [==============================] - 9s 369ms/step - loss: 0.0668 - accuracy: 0.9765 - val_loss: 1.6770 - val_accuracy: 0.7532\n",
      "Epoch 276/700\n",
      "23/23 [==============================] - 9s 376ms/step - loss: 0.0681 - accuracy: 0.9761 - val_loss: 1.6980 - val_accuracy: 0.7521\n",
      "Epoch 277/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0673 - accuracy: 0.9761 - val_loss: 1.6787 - val_accuracy: 0.7516\n",
      "Epoch 278/700\n",
      "23/23 [==============================] - 9s 389ms/step - loss: 0.0678 - accuracy: 0.9762 - val_loss: 1.7259 - val_accuracy: 0.7558\n",
      "Epoch 279/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0677 - accuracy: 0.9756 - val_loss: 1.7304 - val_accuracy: 0.7537\n",
      "Epoch 280/700\n",
      "23/23 [==============================] - 9s 373ms/step - loss: 0.0680 - accuracy: 0.9764 - val_loss: 1.6959 - val_accuracy: 0.7553\n",
      "Epoch 281/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0679 - accuracy: 0.9756 - val_loss: 1.6813 - val_accuracy: 0.7553\n",
      "Epoch 282/700\n",
      "23/23 [==============================] - 8s 369ms/step - loss: 0.0699 - accuracy: 0.9753 - val_loss: 1.7217 - val_accuracy: 0.7479\n",
      "Epoch 283/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0712 - accuracy: 0.9751 - val_loss: 1.6406 - val_accuracy: 0.7505\n",
      "Epoch 284/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0642 - accuracy: 0.9777 - val_loss: 1.6775 - val_accuracy: 0.7563\n",
      "Epoch 285/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0645 - accuracy: 0.9768 - val_loss: 1.6711 - val_accuracy: 0.7526\n",
      "Epoch 286/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0657 - accuracy: 0.9758 - val_loss: 1.6869 - val_accuracy: 0.7532\n",
      "Epoch 287/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0657 - accuracy: 0.9764 - val_loss: 1.6719 - val_accuracy: 0.7542\n",
      "Epoch 288/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0667 - accuracy: 0.9758 - val_loss: 1.6677 - val_accuracy: 0.7521\n",
      "Epoch 289/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0671 - accuracy: 0.9762 - val_loss: 1.6642 - val_accuracy: 0.7521\n",
      "Epoch 290/700\n",
      "23/23 [==============================] - 9s 387ms/step - loss: 0.0665 - accuracy: 0.9781 - val_loss: 1.6183 - val_accuracy: 0.7589\n",
      "Epoch 291/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0684 - accuracy: 0.9765 - val_loss: 1.6496 - val_accuracy: 0.7447\n",
      "Epoch 292/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0641 - accuracy: 0.9785 - val_loss: 1.6479 - val_accuracy: 0.7532\n",
      "Epoch 293/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0661 - accuracy: 0.9775 - val_loss: 1.6443 - val_accuracy: 0.7595\n",
      "Epoch 294/700\n",
      "23/23 [==============================] - 9s 377ms/step - loss: 0.0697 - accuracy: 0.9762 - val_loss: 1.6576 - val_accuracy: 0.7484\n",
      "Epoch 295/700\n",
      "23/23 [==============================] - 9s 374ms/step - loss: 0.0809 - accuracy: 0.9740 - val_loss: 1.6748 - val_accuracy: 0.7532\n",
      "Epoch 296/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0625 - accuracy: 0.9765 - val_loss: 1.6561 - val_accuracy: 0.7568\n",
      "Epoch 297/700\n",
      "23/23 [==============================] - 9s 405ms/step - loss: 0.0632 - accuracy: 0.9775 - val_loss: 1.6686 - val_accuracy: 0.7511\n",
      "Epoch 298/700\n",
      "23/23 [==============================] - 9s 390ms/step - loss: 0.0624 - accuracy: 0.9779 - val_loss: 1.6657 - val_accuracy: 0.7526\n",
      "Epoch 299/700\n",
      "23/23 [==============================] - 9s 378ms/step - loss: 0.0636 - accuracy: 0.9779 - val_loss: 1.6953 - val_accuracy: 0.7521\n",
      "Epoch 300/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 0.0619 - accuracy: 0.9775 - val_loss: 1.7014 - val_accuracy: 0.7610\n",
      "Epoch 301/700\n",
      "23/23 [==============================] - 9s 386ms/step - loss: 0.0622 - accuracy: 0.9774 - val_loss: 1.7000 - val_accuracy: 0.7532\n",
      "Epoch 302/700\n",
      "23/23 [==============================] - 9s 380ms/step - loss: 0.0616 - accuracy: 0.9773 - val_loss: 1.7208 - val_accuracy: 0.7516\n",
      "Epoch 303/700\n",
      "23/23 [==============================] - 9s 373ms/step - loss: 0.0617 - accuracy: 0.9789 - val_loss: 1.7247 - val_accuracy: 0.7600\n",
      "Epoch 304/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0612 - accuracy: 0.9785 - val_loss: 1.6934 - val_accuracy: 0.7563\n",
      "Epoch 305/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0617 - accuracy: 0.9773 - val_loss: 1.7278 - val_accuracy: 0.7584\n",
      "Epoch 306/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0614 - accuracy: 0.9779 - val_loss: 1.7088 - val_accuracy: 0.7542\n",
      "Epoch 307/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0608 - accuracy: 0.9774 - val_loss: 1.7285 - val_accuracy: 0.7574\n",
      "Epoch 308/700\n",
      "23/23 [==============================] - 9s 389ms/step - loss: 0.0710 - accuracy: 0.9765 - val_loss: 1.6839 - val_accuracy: 0.7479\n",
      "Epoch 309/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0628 - accuracy: 0.9772 - val_loss: 1.6919 - val_accuracy: 0.7479\n",
      "Epoch 310/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0976 - accuracy: 0.9716 - val_loss: 1.6986 - val_accuracy: 0.7631\n",
      "Epoch 311/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0729 - accuracy: 0.9768 - val_loss: 1.6919 - val_accuracy: 0.7553\n",
      "Epoch 312/700\n",
      "23/23 [==============================] - 9s 377ms/step - loss: 0.0650 - accuracy: 0.9766 - val_loss: 1.6611 - val_accuracy: 0.7595\n",
      "Epoch 313/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0663 - accuracy: 0.9770 - val_loss: 1.6578 - val_accuracy: 0.7584\n",
      "Epoch 314/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0647 - accuracy: 0.9764 - val_loss: 1.5854 - val_accuracy: 0.7642\n",
      "Epoch 315/700\n",
      "23/23 [==============================] - 9s 397ms/step - loss: 0.0694 - accuracy: 0.9760 - val_loss: 1.6544 - val_accuracy: 0.7532\n",
      "Epoch 316/700\n",
      "23/23 [==============================] - 9s 380ms/step - loss: 0.0592 - accuracy: 0.9785 - val_loss: 1.6772 - val_accuracy: 0.7537\n",
      "Epoch 317/700\n",
      "23/23 [==============================] - 9s 379ms/step - loss: 0.0594 - accuracy: 0.9796 - val_loss: 1.6824 - val_accuracy: 0.7495\n",
      "Epoch 318/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0603 - accuracy: 0.9775 - val_loss: 1.6764 - val_accuracy: 0.7574\n",
      "Epoch 319/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0599 - accuracy: 0.9781 - val_loss: 1.6896 - val_accuracy: 0.7558\n",
      "Epoch 320/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0586 - accuracy: 0.9789 - val_loss: 1.7155 - val_accuracy: 0.7537\n",
      "Epoch 321/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0597 - accuracy: 0.9787 - val_loss: 1.7168 - val_accuracy: 0.7542\n",
      "Epoch 322/700\n",
      "23/23 [==============================] - 9s 369ms/step - loss: 0.0588 - accuracy: 0.9786 - val_loss: 1.7363 - val_accuracy: 0.7495\n",
      "Epoch 323/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0590 - accuracy: 0.9789 - val_loss: 1.7408 - val_accuracy: 0.7521\n",
      "Epoch 324/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0711 - accuracy: 0.9756 - val_loss: 1.6465 - val_accuracy: 0.7563\n",
      "Epoch 325/700\n",
      "23/23 [==============================] - 9s 373ms/step - loss: 0.0757 - accuracy: 0.9715 - val_loss: 1.7107 - val_accuracy: 0.7516\n",
      "Epoch 326/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0704 - accuracy: 0.9743 - val_loss: 1.6432 - val_accuracy: 0.7616\n",
      "Epoch 327/700\n",
      "23/23 [==============================] - 9s 371ms/step - loss: 0.0697 - accuracy: 0.9740 - val_loss: 1.7173 - val_accuracy: 0.7432\n",
      "Epoch 328/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0678 - accuracy: 0.9740 - val_loss: 1.6694 - val_accuracy: 0.7574\n",
      "Epoch 329/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0671 - accuracy: 0.9758 - val_loss: 1.6983 - val_accuracy: 0.7511\n",
      "Epoch 330/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0695 - accuracy: 0.9749 - val_loss: 1.7222 - val_accuracy: 0.7532\n",
      "Epoch 331/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0641 - accuracy: 0.9768 - val_loss: 1.7099 - val_accuracy: 0.7532\n",
      "Epoch 332/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0655 - accuracy: 0.9775 - val_loss: 1.7278 - val_accuracy: 0.7442\n",
      "Epoch 333/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0704 - accuracy: 0.9761 - val_loss: 1.7419 - val_accuracy: 0.7442\n",
      "Epoch 334/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0704 - accuracy: 0.9743 - val_loss: 1.6884 - val_accuracy: 0.7511\n",
      "Epoch 335/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0704 - accuracy: 0.9756 - val_loss: 1.7261 - val_accuracy: 0.7526\n",
      "Epoch 336/700\n",
      "23/23 [==============================] - 9s 370ms/step - loss: 0.0674 - accuracy: 0.9762 - val_loss: 1.7099 - val_accuracy: 0.7495\n",
      "Epoch 337/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0663 - accuracy: 0.9765 - val_loss: 1.7031 - val_accuracy: 0.7584\n",
      "Epoch 338/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0667 - accuracy: 0.9753 - val_loss: 1.7331 - val_accuracy: 0.7437\n",
      "Epoch 339/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0672 - accuracy: 0.9753 - val_loss: 1.7279 - val_accuracy: 0.7484\n",
      "Epoch 340/700\n",
      "23/23 [==============================] - 9s 371ms/step - loss: 0.0655 - accuracy: 0.9762 - val_loss: 1.6815 - val_accuracy: 0.7558\n",
      "Epoch 341/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0632 - accuracy: 0.9769 - val_loss: 1.6977 - val_accuracy: 0.7526\n",
      "Epoch 342/700\n",
      "23/23 [==============================] - 8s 338ms/step - loss: 0.0616 - accuracy: 0.9781 - val_loss: 1.7122 - val_accuracy: 0.7568\n",
      "Epoch 343/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0605 - accuracy: 0.9786 - val_loss: 1.7064 - val_accuracy: 0.7558\n",
      "Epoch 344/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0617 - accuracy: 0.9785 - val_loss: 1.7152 - val_accuracy: 0.7532\n",
      "Epoch 345/700\n",
      "23/23 [==============================] - 8s 370ms/step - loss: 0.0595 - accuracy: 0.9791 - val_loss: 1.7334 - val_accuracy: 0.7511\n",
      "Epoch 346/700\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0606 - accuracy: 0.9791 - val_loss: 1.7212 - val_accuracy: 0.7563\n",
      "Epoch 347/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0587 - accuracy: 0.9783 - val_loss: 1.7227 - val_accuracy: 0.7526\n",
      "Epoch 348/700\n",
      "23/23 [==============================] - 9s 371ms/step - loss: 0.0617 - accuracy: 0.9779 - val_loss: 1.7179 - val_accuracy: 0.7500\n",
      "Epoch 349/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0622 - accuracy: 0.9782 - val_loss: 1.7463 - val_accuracy: 0.7505\n",
      "Epoch 350/700\n",
      "23/23 [==============================] - 8s 339ms/step - loss: 0.0622 - accuracy: 0.9772 - val_loss: 1.7689 - val_accuracy: 0.7495\n",
      "Epoch 351/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0608 - accuracy: 0.9783 - val_loss: 1.7815 - val_accuracy: 0.7463\n",
      "Epoch 352/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0608 - accuracy: 0.9787 - val_loss: 1.7612 - val_accuracy: 0.7526\n",
      "Epoch 353/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0611 - accuracy: 0.9791 - val_loss: 1.7749 - val_accuracy: 0.7447\n",
      "Epoch 354/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0609 - accuracy: 0.9781 - val_loss: 1.7581 - val_accuracy: 0.7532\n",
      "Epoch 355/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0597 - accuracy: 0.9802 - val_loss: 1.7798 - val_accuracy: 0.7468\n",
      "Epoch 356/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0592 - accuracy: 0.9789 - val_loss: 1.7683 - val_accuracy: 0.7437\n",
      "Epoch 357/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0592 - accuracy: 0.9791 - val_loss: 1.7901 - val_accuracy: 0.7463\n",
      "Epoch 358/700\n",
      "23/23 [==============================] - 9s 388ms/step - loss: 0.0593 - accuracy: 0.9781 - val_loss: 1.7842 - val_accuracy: 0.7505\n",
      "Epoch 359/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0591 - accuracy: 0.9799 - val_loss: 1.7862 - val_accuracy: 0.7505\n",
      "Epoch 360/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0582 - accuracy: 0.9798 - val_loss: 1.8043 - val_accuracy: 0.7511\n",
      "Epoch 361/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0582 - accuracy: 0.9791 - val_loss: 1.8140 - val_accuracy: 0.7505\n",
      "Epoch 362/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0575 - accuracy: 0.9800 - val_loss: 1.8717 - val_accuracy: 0.7416\n",
      "Epoch 363/700\n",
      "23/23 [==============================] - 8s 339ms/step - loss: 0.0688 - accuracy: 0.9764 - val_loss: 1.6701 - val_accuracy: 0.7511\n",
      "Epoch 364/700\n",
      "23/23 [==============================] - 9s 381ms/step - loss: 0.0626 - accuracy: 0.9785 - val_loss: 1.7354 - val_accuracy: 0.7453\n",
      "Epoch 365/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0557 - accuracy: 0.9811 - val_loss: 1.7425 - val_accuracy: 0.7500\n",
      "Epoch 366/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0569 - accuracy: 0.9795 - val_loss: 1.7480 - val_accuracy: 0.7479\n",
      "Epoch 367/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0570 - accuracy: 0.9796 - val_loss: 1.7806 - val_accuracy: 0.7500\n",
      "Epoch 368/700\n",
      "23/23 [==============================] - 8s 336ms/step - loss: 0.0669 - accuracy: 0.9768 - val_loss: 1.6949 - val_accuracy: 0.7505\n",
      "Epoch 369/700\n",
      "23/23 [==============================] - 8s 330ms/step - loss: 0.0592 - accuracy: 0.9799 - val_loss: 1.7632 - val_accuracy: 0.7432\n",
      "Epoch 370/700\n",
      "23/23 [==============================] - 8s 336ms/step - loss: 0.0620 - accuracy: 0.9783 - val_loss: 1.7798 - val_accuracy: 0.7384\n",
      "Epoch 371/700\n",
      "23/23 [==============================] - 8s 339ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 1.7452 - val_accuracy: 0.7505\n",
      "Epoch 372/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0557 - accuracy: 0.9802 - val_loss: 1.7300 - val_accuracy: 0.7511\n",
      "Epoch 373/700\n",
      "23/23 [==============================] - 8s 338ms/step - loss: 0.0561 - accuracy: 0.9814 - val_loss: 1.7784 - val_accuracy: 0.7489\n",
      "Epoch 374/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0549 - accuracy: 0.9796 - val_loss: 1.7334 - val_accuracy: 0.7426\n",
      "Epoch 375/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0550 - accuracy: 0.9806 - val_loss: 1.7606 - val_accuracy: 0.7453\n",
      "Epoch 376/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0552 - accuracy: 0.9806 - val_loss: 1.7890 - val_accuracy: 0.7468\n",
      "Epoch 377/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0572 - accuracy: 0.9791 - val_loss: 1.7608 - val_accuracy: 0.7500\n",
      "Epoch 378/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0580 - accuracy: 0.9789 - val_loss: 1.7963 - val_accuracy: 0.7521\n",
      "Epoch 379/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0558 - accuracy: 0.9800 - val_loss: 1.7948 - val_accuracy: 0.7521\n",
      "Epoch 380/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0582 - accuracy: 0.9793 - val_loss: 1.8071 - val_accuracy: 0.7532\n",
      "Epoch 381/700\n",
      "23/23 [==============================] - 8s 338ms/step - loss: 0.0780 - accuracy: 0.9752 - val_loss: 1.9133 - val_accuracy: 0.7358\n",
      "Epoch 382/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0761 - accuracy: 0.9741 - val_loss: 1.8257 - val_accuracy: 0.7421\n",
      "Epoch 383/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0653 - accuracy: 0.9774 - val_loss: 1.7669 - val_accuracy: 0.7479\n",
      "Epoch 384/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0647 - accuracy: 0.9758 - val_loss: 1.7484 - val_accuracy: 0.7558\n",
      "Epoch 385/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0676 - accuracy: 0.9768 - val_loss: 1.7841 - val_accuracy: 0.7479\n",
      "Epoch 386/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0676 - accuracy: 0.9768 - val_loss: 1.7574 - val_accuracy: 0.7542\n",
      "Epoch 387/700\n",
      "23/23 [==============================] - 8s 370ms/step - loss: 0.0598 - accuracy: 0.9787 - val_loss: 1.7500 - val_accuracy: 0.7453\n",
      "Epoch 388/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0619 - accuracy: 0.9785 - val_loss: 1.7203 - val_accuracy: 0.7542\n",
      "Epoch 389/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0591 - accuracy: 0.9799 - val_loss: 1.7784 - val_accuracy: 0.7453\n",
      "Epoch 390/700\n",
      "23/23 [==============================] - 9s 377ms/step - loss: 0.0564 - accuracy: 0.9795 - val_loss: 1.7643 - val_accuracy: 0.7432\n",
      "Epoch 391/700\n",
      "23/23 [==============================] - 9s 385ms/step - loss: 0.0556 - accuracy: 0.9804 - val_loss: 1.7666 - val_accuracy: 0.7484\n",
      "Epoch 392/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0562 - accuracy: 0.9795 - val_loss: 1.7466 - val_accuracy: 0.7479\n",
      "Epoch 393/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0579 - accuracy: 0.9798 - val_loss: 1.7109 - val_accuracy: 0.7468\n",
      "Epoch 394/700\n",
      "23/23 [==============================] - 9s 376ms/step - loss: 0.0570 - accuracy: 0.9798 - val_loss: 1.7166 - val_accuracy: 0.7610\n",
      "Epoch 395/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 9s 387ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 1.6713 - val_accuracy: 0.7584\n",
      "Epoch 396/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0542 - accuracy: 0.9812 - val_loss: 1.7230 - val_accuracy: 0.7563\n",
      "Epoch 397/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0547 - accuracy: 0.9802 - val_loss: 1.6974 - val_accuracy: 0.7652\n",
      "Epoch 398/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0555 - accuracy: 0.9799 - val_loss: 1.7166 - val_accuracy: 0.7610\n",
      "Epoch 399/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0555 - accuracy: 0.9799 - val_loss: 1.7630 - val_accuracy: 0.7584\n",
      "Epoch 400/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0552 - accuracy: 0.9804 - val_loss: 1.7638 - val_accuracy: 0.7532\n",
      "Epoch 401/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0543 - accuracy: 0.9799 - val_loss: 1.7552 - val_accuracy: 0.7568\n",
      "Epoch 402/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0542 - accuracy: 0.9803 - val_loss: 1.7669 - val_accuracy: 0.7547\n",
      "Epoch 403/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0551 - accuracy: 0.9811 - val_loss: 1.8097 - val_accuracy: 0.7489\n",
      "Epoch 404/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 0.0535 - accuracy: 0.9806 - val_loss: 1.7964 - val_accuracy: 0.7516\n",
      "Epoch 405/700\n",
      "23/23 [==============================] - 9s 394ms/step - loss: 0.0534 - accuracy: 0.9802 - val_loss: 1.8053 - val_accuracy: 0.7516\n",
      "Epoch 406/700\n",
      "23/23 [==============================] - 9s 383ms/step - loss: 0.0543 - accuracy: 0.9802 - val_loss: 1.8058 - val_accuracy: 0.7526\n",
      "Epoch 407/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0542 - accuracy: 0.9799 - val_loss: 1.8074 - val_accuracy: 0.7511\n",
      "Epoch 408/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0564 - accuracy: 0.9795 - val_loss: 1.7850 - val_accuracy: 0.7511\n",
      "Epoch 409/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0527 - accuracy: 0.9819 - val_loss: 1.7939 - val_accuracy: 0.7495\n",
      "Epoch 410/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0539 - accuracy: 0.9821 - val_loss: 1.7092 - val_accuracy: 0.7605\n",
      "Epoch 411/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0616 - accuracy: 0.9791 - val_loss: 1.7954 - val_accuracy: 0.7553\n",
      "Epoch 412/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0558 - accuracy: 0.9808 - val_loss: 1.7278 - val_accuracy: 0.7637\n",
      "Epoch 413/700\n",
      "23/23 [==============================] - 9s 383ms/step - loss: 0.0573 - accuracy: 0.9796 - val_loss: 1.7883 - val_accuracy: 0.7563\n",
      "Epoch 414/700\n",
      "23/23 [==============================] - 9s 388ms/step - loss: 0.0588 - accuracy: 0.9795 - val_loss: 1.7542 - val_accuracy: 0.7568\n",
      "Epoch 415/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0600 - accuracy: 0.9802 - val_loss: 1.7771 - val_accuracy: 0.7605\n",
      "Epoch 416/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0555 - accuracy: 0.9804 - val_loss: 1.7651 - val_accuracy: 0.7553\n",
      "Epoch 417/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0582 - accuracy: 0.9796 - val_loss: 1.7436 - val_accuracy: 0.7621\n",
      "Epoch 418/700\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0562 - accuracy: 0.9802 - val_loss: 1.7503 - val_accuracy: 0.7616\n",
      "Epoch 419/700\n",
      "23/23 [==============================] - 8s 339ms/step - loss: 0.0588 - accuracy: 0.9790 - val_loss: 1.7160 - val_accuracy: 0.7689\n",
      "Epoch 420/700\n",
      "23/23 [==============================] - 9s 374ms/step - loss: 0.0587 - accuracy: 0.9790 - val_loss: 1.7326 - val_accuracy: 0.7647\n",
      "Epoch 421/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0574 - accuracy: 0.9799 - val_loss: 1.7022 - val_accuracy: 0.7673\n",
      "Epoch 422/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0650 - accuracy: 0.9768 - val_loss: 1.7593 - val_accuracy: 0.7631\n",
      "Epoch 423/700\n",
      "23/23 [==============================] - 9s 380ms/step - loss: 0.0577 - accuracy: 0.9791 - val_loss: 1.7538 - val_accuracy: 0.7616\n",
      "Epoch 424/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 0.0578 - accuracy: 0.9786 - val_loss: 1.7427 - val_accuracy: 0.7605\n",
      "Epoch 425/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0616 - accuracy: 0.9782 - val_loss: 1.7411 - val_accuracy: 0.7595\n",
      "Epoch 426/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0589 - accuracy: 0.9785 - val_loss: 1.7480 - val_accuracy: 0.7605\n",
      "Epoch 427/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0562 - accuracy: 0.9791 - val_loss: 1.7445 - val_accuracy: 0.7579\n",
      "Epoch 428/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 1.7663 - val_accuracy: 0.7616\n",
      "Epoch 429/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0538 - accuracy: 0.9793 - val_loss: 1.7322 - val_accuracy: 0.7610\n",
      "Epoch 430/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0543 - accuracy: 0.9800 - val_loss: 1.7557 - val_accuracy: 0.7574\n",
      "Epoch 431/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0541 - accuracy: 0.9804 - val_loss: 1.7464 - val_accuracy: 0.7526\n",
      "Epoch 432/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 1.7157 - val_accuracy: 0.7595\n",
      "Epoch 433/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0534 - accuracy: 0.9808 - val_loss: 1.7642 - val_accuracy: 0.7479\n",
      "Epoch 434/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0529 - accuracy: 0.9808 - val_loss: 1.7740 - val_accuracy: 0.7526\n",
      "Epoch 435/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0525 - accuracy: 0.9804 - val_loss: 1.8109 - val_accuracy: 0.7526\n",
      "Epoch 436/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0519 - accuracy: 0.9804 - val_loss: 1.7621 - val_accuracy: 0.7568\n",
      "Epoch 437/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 1.7648 - val_accuracy: 0.7574\n",
      "Epoch 438/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0522 - accuracy: 0.9812 - val_loss: 1.8105 - val_accuracy: 0.7563\n",
      "Epoch 439/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0526 - accuracy: 0.9796 - val_loss: 1.7914 - val_accuracy: 0.7616\n",
      "Epoch 440/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0529 - accuracy: 0.9800 - val_loss: 1.7954 - val_accuracy: 0.7584\n",
      "Epoch 441/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0503 - accuracy: 0.9812 - val_loss: 1.7855 - val_accuracy: 0.7605\n",
      "Epoch 442/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0522 - accuracy: 0.9814 - val_loss: 1.7835 - val_accuracy: 0.7605\n",
      "Epoch 443/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0507 - accuracy: 0.9814 - val_loss: 1.8049 - val_accuracy: 0.7547\n",
      "Epoch 444/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0534 - accuracy: 0.9795 - val_loss: 1.8176 - val_accuracy: 0.7579\n",
      "Epoch 445/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 1.7865 - val_accuracy: 0.7589\n",
      "Epoch 446/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0503 - accuracy: 0.9816 - val_loss: 1.8070 - val_accuracy: 0.7574\n",
      "Epoch 447/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0507 - accuracy: 0.9816 - val_loss: 1.7911 - val_accuracy: 0.7589\n",
      "Epoch 448/700\n",
      "23/23 [==============================] - 9s 373ms/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 1.7992 - val_accuracy: 0.7584\n",
      "Epoch 449/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 1.8332 - val_accuracy: 0.7526\n",
      "Epoch 450/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0512 - accuracy: 0.9806 - val_loss: 1.8377 - val_accuracy: 0.7553\n",
      "Epoch 451/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0522 - accuracy: 0.9807 - val_loss: 1.8573 - val_accuracy: 0.7542\n",
      "Epoch 452/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0507 - accuracy: 0.9817 - val_loss: 1.8745 - val_accuracy: 0.7511\n",
      "Epoch 453/700\n",
      "23/23 [==============================] - 8s 333ms/step - loss: 0.0509 - accuracy: 0.9825 - val_loss: 1.8609 - val_accuracy: 0.7500\n",
      "Epoch 454/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0509 - accuracy: 0.9806 - val_loss: 1.8561 - val_accuracy: 0.7511\n",
      "Epoch 455/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0502 - accuracy: 0.9821 - val_loss: 1.8701 - val_accuracy: 0.7505\n",
      "Epoch 456/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0515 - accuracy: 0.9812 - val_loss: 1.8784 - val_accuracy: 0.7526\n",
      "Epoch 457/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0521 - accuracy: 0.9819 - val_loss: 1.9122 - val_accuracy: 0.7437\n",
      "Epoch 458/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0537 - accuracy: 0.9808 - val_loss: 1.8774 - val_accuracy: 0.7442\n",
      "Epoch 459/700\n",
      "23/23 [==============================] - 8s 331ms/step - loss: 0.0524 - accuracy: 0.9811 - val_loss: 1.8302 - val_accuracy: 0.7537\n",
      "Epoch 460/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 1.8371 - val_accuracy: 0.7458\n",
      "Epoch 461/700\n",
      "23/23 [==============================] - 9s 381ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 2.0144 - val_accuracy: 0.7369\n",
      "Epoch 462/700\n",
      "23/23 [==============================] - 8s 370ms/step - loss: 0.0576 - accuracy: 0.9804 - val_loss: 1.9113 - val_accuracy: 0.7474\n",
      "Epoch 463/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0510 - accuracy: 0.9811 - val_loss: 1.9184 - val_accuracy: 0.7421\n",
      "Epoch 464/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0491 - accuracy: 0.9823 - val_loss: 1.9065 - val_accuracy: 0.7421\n",
      "Epoch 465/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 1.8882 - val_accuracy: 0.7453\n",
      "Epoch 466/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0584 - accuracy: 0.9791 - val_loss: 1.8954 - val_accuracy: 0.7411\n",
      "Epoch 467/700\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0496 - accuracy: 0.9817 - val_loss: 1.8654 - val_accuracy: 0.7395\n",
      "Epoch 468/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0579 - accuracy: 0.9803 - val_loss: 1.9445 - val_accuracy: 0.7453\n",
      "Epoch 469/700\n",
      "23/23 [==============================] - 8s 338ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 1.8770 - val_accuracy: 0.7405\n",
      "Epoch 470/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0521 - accuracy: 0.9823 - val_loss: 1.8691 - val_accuracy: 0.7500\n",
      "Epoch 471/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0494 - accuracy: 0.9821 - val_loss: 1.8544 - val_accuracy: 0.7500\n",
      "Epoch 472/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0518 - accuracy: 0.9814 - val_loss: 1.8552 - val_accuracy: 0.7553\n",
      "Epoch 473/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0513 - accuracy: 0.9823 - val_loss: 1.8433 - val_accuracy: 0.7553\n",
      "Epoch 474/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0498 - accuracy: 0.9815 - val_loss: 1.8692 - val_accuracy: 0.7521\n",
      "Epoch 475/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0501 - accuracy: 0.9819 - val_loss: 1.9173 - val_accuracy: 0.7390\n",
      "Epoch 476/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0495 - accuracy: 0.9824 - val_loss: 1.8544 - val_accuracy: 0.7516\n",
      "Epoch 477/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 1.8453 - val_accuracy: 0.7547\n",
      "Epoch 478/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0489 - accuracy: 0.9824 - val_loss: 1.9021 - val_accuracy: 0.7474\n",
      "Epoch 479/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0491 - accuracy: 0.9824 - val_loss: 1.8354 - val_accuracy: 0.7521\n",
      "Epoch 480/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0510 - accuracy: 0.9816 - val_loss: 1.8897 - val_accuracy: 0.7526\n",
      "Epoch 481/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0586 - accuracy: 0.9807 - val_loss: 1.8304 - val_accuracy: 0.7511\n",
      "Epoch 482/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0503 - accuracy: 0.9815 - val_loss: 1.8588 - val_accuracy: 0.7479\n",
      "Epoch 483/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0527 - accuracy: 0.9812 - val_loss: 1.8209 - val_accuracy: 0.7553\n",
      "Epoch 484/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0512 - accuracy: 0.9821 - val_loss: 1.8918 - val_accuracy: 0.7621\n",
      "Epoch 485/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0502 - accuracy: 0.9819 - val_loss: 1.9155 - val_accuracy: 0.7526\n",
      "Epoch 486/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0499 - accuracy: 0.9820 - val_loss: 1.8620 - val_accuracy: 0.7558\n",
      "Epoch 487/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0571 - accuracy: 0.9803 - val_loss: 1.8574 - val_accuracy: 0.7584\n",
      "Epoch 488/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0493 - accuracy: 0.9817 - val_loss: 1.8539 - val_accuracy: 0.7574\n",
      "Epoch 489/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0493 - accuracy: 0.9816 - val_loss: 1.8806 - val_accuracy: 0.7495\n",
      "Epoch 490/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 1.9214 - val_accuracy: 0.7500\n",
      "Epoch 491/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0491 - accuracy: 0.9820 - val_loss: 1.9152 - val_accuracy: 0.7542\n",
      "Epoch 492/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0494 - accuracy: 0.9821 - val_loss: 1.9214 - val_accuracy: 0.7574\n",
      "Epoch 493/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0492 - accuracy: 0.9820 - val_loss: 1.9569 - val_accuracy: 0.7526\n",
      "Epoch 494/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0501 - accuracy: 0.9815 - val_loss: 1.9308 - val_accuracy: 0.7537\n",
      "Epoch 495/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0489 - accuracy: 0.9823 - val_loss: 1.9625 - val_accuracy: 0.7547\n",
      "Epoch 496/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0497 - accuracy: 0.9819 - val_loss: 1.9712 - val_accuracy: 0.7537\n",
      "Epoch 497/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0500 - accuracy: 0.9820 - val_loss: 1.9651 - val_accuracy: 0.7542\n",
      "Epoch 498/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0478 - accuracy: 0.9827 - val_loss: 1.9642 - val_accuracy: 0.7489\n",
      "Epoch 499/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0529 - accuracy: 0.9819 - val_loss: 1.9861 - val_accuracy: 0.7542\n",
      "Epoch 500/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 1.8779 - val_accuracy: 0.7547\n",
      "Epoch 501/700\n",
      "23/23 [==============================] - 9s 382ms/step - loss: 0.0622 - accuracy: 0.9794 - val_loss: 1.9331 - val_accuracy: 0.7411\n",
      "Epoch 502/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 1.9031 - val_accuracy: 0.7526\n",
      "Epoch 503/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0549 - accuracy: 0.9808 - val_loss: 1.9350 - val_accuracy: 0.7537\n",
      "Epoch 504/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0535 - accuracy: 0.9819 - val_loss: 1.9117 - val_accuracy: 0.7516\n",
      "Epoch 505/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0526 - accuracy: 0.9819 - val_loss: 1.9353 - val_accuracy: 0.7553\n",
      "Epoch 506/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 1.9275 - val_accuracy: 0.7574\n",
      "Epoch 507/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0521 - accuracy: 0.9821 - val_loss: 1.9391 - val_accuracy: 0.7532\n",
      "Epoch 508/700\n",
      "23/23 [==============================] - 8s 370ms/step - loss: 0.0533 - accuracy: 0.9814 - val_loss: 1.9742 - val_accuracy: 0.7532\n",
      "Epoch 509/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0544 - accuracy: 0.9807 - val_loss: 1.9386 - val_accuracy: 0.7553\n",
      "Epoch 510/700\n",
      "23/23 [==============================] - 8s 369ms/step - loss: 0.0487 - accuracy: 0.9827 - val_loss: 2.0029 - val_accuracy: 0.7484\n",
      "Epoch 511/700\n",
      "23/23 [==============================] - 9s 390ms/step - loss: 0.0506 - accuracy: 0.9820 - val_loss: 1.9461 - val_accuracy: 0.7521\n",
      "Epoch 512/700\n",
      "23/23 [==============================] - 9s 377ms/step - loss: 0.0508 - accuracy: 0.9828 - val_loss: 1.9892 - val_accuracy: 0.7521\n",
      "Epoch 513/700\n",
      "23/23 [==============================] - 8s 370ms/step - loss: 0.0495 - accuracy: 0.9824 - val_loss: 2.0029 - val_accuracy: 0.7453\n",
      "Epoch 514/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0469 - accuracy: 0.9827 - val_loss: 1.9778 - val_accuracy: 0.7484\n",
      "Epoch 515/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0496 - accuracy: 0.9816 - val_loss: 2.0307 - val_accuracy: 0.7453\n",
      "Epoch 516/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0506 - accuracy: 0.9824 - val_loss: 2.0042 - val_accuracy: 0.7437\n",
      "Epoch 517/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 0.0481 - accuracy: 0.9821 - val_loss: 2.0179 - val_accuracy: 0.7405\n",
      "Epoch 518/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 2.0201 - val_accuracy: 0.7390\n",
      "Epoch 519/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0475 - accuracy: 0.9824 - val_loss: 1.9991 - val_accuracy: 0.7468\n",
      "Epoch 520/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0497 - accuracy: 0.9820 - val_loss: 1.9977 - val_accuracy: 0.7421\n",
      "Epoch 521/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0467 - accuracy: 0.9825 - val_loss: 1.9961 - val_accuracy: 0.7426\n",
      "Epoch 522/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0501 - accuracy: 0.9828 - val_loss: 2.0070 - val_accuracy: 0.7411\n",
      "Epoch 523/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0460 - accuracy: 0.9831 - val_loss: 2.0155 - val_accuracy: 0.7421\n",
      "Epoch 524/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0548 - accuracy: 0.9815 - val_loss: 2.0850 - val_accuracy: 0.7405\n",
      "Epoch 525/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0547 - accuracy: 0.9804 - val_loss: 2.0474 - val_accuracy: 0.7468\n",
      "Epoch 526/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 2.0305 - val_accuracy: 0.7437\n",
      "Epoch 527/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 2.0502 - val_accuracy: 0.7489\n",
      "Epoch 528/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 2.0763 - val_accuracy: 0.7479\n",
      "Epoch 529/700\n",
      "23/23 [==============================] - 8s 339ms/step - loss: 0.0514 - accuracy: 0.9820 - val_loss: 2.0478 - val_accuracy: 0.7495\n",
      "Epoch 530/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0506 - accuracy: 0.9825 - val_loss: 2.1237 - val_accuracy: 0.7405\n",
      "Epoch 531/700\n",
      "23/23 [==============================] - 9s 378ms/step - loss: 0.0530 - accuracy: 0.9824 - val_loss: 2.1398 - val_accuracy: 0.7474\n",
      "Epoch 532/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0529 - accuracy: 0.9812 - val_loss: 2.0610 - val_accuracy: 0.7489\n",
      "Epoch 533/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0521 - accuracy: 0.9820 - val_loss: 2.0540 - val_accuracy: 0.7479\n",
      "Epoch 534/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0528 - accuracy: 0.9816 - val_loss: 2.0827 - val_accuracy: 0.7374\n",
      "Epoch 535/700\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0493 - accuracy: 0.9819 - val_loss: 2.0624 - val_accuracy: 0.7421\n",
      "Epoch 536/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 2.0554 - val_accuracy: 0.7432\n",
      "Epoch 537/700\n",
      "23/23 [==============================] - 8s 335ms/step - loss: 0.0472 - accuracy: 0.9823 - val_loss: 2.0713 - val_accuracy: 0.7421\n",
      "Epoch 538/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0509 - accuracy: 0.9823 - val_loss: 2.0378 - val_accuracy: 0.7405\n",
      "Epoch 539/700\n",
      "23/23 [==============================] - 9s 382ms/step - loss: 0.0465 - accuracy: 0.9821 - val_loss: 2.0487 - val_accuracy: 0.7458\n",
      "Epoch 540/700\n",
      "23/23 [==============================] - 8s 334ms/step - loss: 0.0463 - accuracy: 0.9829 - val_loss: 2.0567 - val_accuracy: 0.7474\n",
      "Epoch 541/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0480 - accuracy: 0.9823 - val_loss: 2.0126 - val_accuracy: 0.7416\n",
      "Epoch 542/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0465 - accuracy: 0.9825 - val_loss: 2.0588 - val_accuracy: 0.7447\n",
      "Epoch 543/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 2.0500 - val_accuracy: 0.7426\n",
      "Epoch 544/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0461 - accuracy: 0.9835 - val_loss: 2.0742 - val_accuracy: 0.7432\n",
      "Epoch 545/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0467 - accuracy: 0.9837 - val_loss: 2.0598 - val_accuracy: 0.7479\n",
      "Epoch 546/700\n",
      "23/23 [==============================] - 8s 336ms/step - loss: 0.0471 - accuracy: 0.9827 - val_loss: 2.0703 - val_accuracy: 0.7405\n",
      "Epoch 547/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0456 - accuracy: 0.9827 - val_loss: 2.0692 - val_accuracy: 0.7421\n",
      "Epoch 548/700\n",
      "23/23 [==============================] - 8s 334ms/step - loss: 0.0478 - accuracy: 0.9832 - val_loss: 2.0681 - val_accuracy: 0.7426\n",
      "Epoch 549/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0447 - accuracy: 0.9837 - val_loss: 2.1427 - val_accuracy: 0.7369\n",
      "Epoch 550/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 2.1179 - val_accuracy: 0.7379\n",
      "Epoch 551/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0462 - accuracy: 0.9823 - val_loss: 2.0962 - val_accuracy: 0.7395\n",
      "Epoch 552/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0456 - accuracy: 0.9835 - val_loss: 2.1288 - val_accuracy: 0.7395\n",
      "Epoch 553/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0449 - accuracy: 0.9832 - val_loss: 2.1193 - val_accuracy: 0.7453\n",
      "Epoch 554/700\n",
      "23/23 [==============================] - 8s 337ms/step - loss: 0.0454 - accuracy: 0.9827 - val_loss: 2.1480 - val_accuracy: 0.7358\n",
      "Epoch 555/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0443 - accuracy: 0.9827 - val_loss: 2.1257 - val_accuracy: 0.7405\n",
      "Epoch 556/700\n",
      "23/23 [==============================] - 8s 339ms/step - loss: 0.0476 - accuracy: 0.9824 - val_loss: 2.1382 - val_accuracy: 0.7353\n",
      "Epoch 557/700\n",
      "23/23 [==============================] - 8s 337ms/step - loss: 0.0590 - accuracy: 0.9815 - val_loss: 2.1041 - val_accuracy: 0.7432\n",
      "Epoch 558/700\n",
      "23/23 [==============================] - 8s 331ms/step - loss: 0.0538 - accuracy: 0.9824 - val_loss: 2.1732 - val_accuracy: 0.7306\n",
      "Epoch 559/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0474 - accuracy: 0.9838 - val_loss: 2.1135 - val_accuracy: 0.7395\n",
      "Epoch 560/700\n",
      "23/23 [==============================] - 8s 369ms/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 2.1146 - val_accuracy: 0.7227\n",
      "Epoch 561/700\n",
      "23/23 [==============================] - 8s 370ms/step - loss: 0.0440 - accuracy: 0.9837 - val_loss: 2.0630 - val_accuracy: 0.7348\n",
      "Epoch 562/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0492 - accuracy: 0.9827 - val_loss: 2.0266 - val_accuracy: 0.7369\n",
      "Epoch 563/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0494 - accuracy: 0.9821 - val_loss: 1.9998 - val_accuracy: 0.7442\n",
      "Epoch 564/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0430 - accuracy: 0.9842 - val_loss: 2.0056 - val_accuracy: 0.7437\n",
      "Epoch 565/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0441 - accuracy: 0.9841 - val_loss: 2.0091 - val_accuracy: 0.7484\n",
      "Epoch 566/700\n",
      "23/23 [==============================] - 8s 339ms/step - loss: 0.0433 - accuracy: 0.9833 - val_loss: 2.0329 - val_accuracy: 0.7500\n",
      "Epoch 567/700\n",
      "23/23 [==============================] - 7s 322ms/step - loss: 0.0431 - accuracy: 0.9832 - val_loss: 2.0260 - val_accuracy: 0.7405\n",
      "Epoch 568/700\n",
      "23/23 [==============================] - 8s 333ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 2.0185 - val_accuracy: 0.7474\n",
      "Epoch 569/700\n",
      "23/23 [==============================] - 8s 369ms/step - loss: 0.0445 - accuracy: 0.9838 - val_loss: 2.0266 - val_accuracy: 0.7511\n",
      "Epoch 570/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0446 - accuracy: 0.9838 - val_loss: 2.0440 - val_accuracy: 0.7447\n",
      "Epoch 571/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0438 - accuracy: 0.9833 - val_loss: 2.0738 - val_accuracy: 0.7479\n",
      "Epoch 572/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0448 - accuracy: 0.9844 - val_loss: 2.0677 - val_accuracy: 0.7489\n",
      "Epoch 573/700\n",
      "23/23 [==============================] - 9s 375ms/step - loss: 0.0443 - accuracy: 0.9832 - val_loss: 2.0433 - val_accuracy: 0.7468\n",
      "Epoch 574/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0440 - accuracy: 0.9836 - val_loss: 2.1068 - val_accuracy: 0.7447\n",
      "Epoch 575/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0535 - accuracy: 0.9824 - val_loss: 2.0610 - val_accuracy: 0.7426\n",
      "Epoch 576/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0549 - accuracy: 0.9817 - val_loss: 2.1139 - val_accuracy: 0.7463\n",
      "Epoch 577/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0509 - accuracy: 0.9823 - val_loss: 2.0511 - val_accuracy: 0.7432\n",
      "Epoch 578/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0469 - accuracy: 0.9836 - val_loss: 2.1946 - val_accuracy: 0.7285\n",
      "Epoch 579/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0417 - accuracy: 0.9849 - val_loss: 2.0300 - val_accuracy: 0.7400\n",
      "Epoch 580/700\n",
      "23/23 [==============================] - 8s 364ms/step - loss: 0.0430 - accuracy: 0.9841 - val_loss: 2.0717 - val_accuracy: 0.7411\n",
      "Epoch 581/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 2.1034 - val_accuracy: 0.7327\n",
      "Epoch 582/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0936 - accuracy: 0.9747 - val_loss: 2.0458 - val_accuracy: 0.7274\n",
      "Epoch 583/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0793 - accuracy: 0.9772 - val_loss: 1.9811 - val_accuracy: 0.7348\n",
      "Epoch 584/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0727 - accuracy: 0.9760 - val_loss: 1.9801 - val_accuracy: 0.7416\n",
      "Epoch 585/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0682 - accuracy: 0.9756 - val_loss: 1.9768 - val_accuracy: 0.7474\n",
      "Epoch 586/700\n",
      "23/23 [==============================] - 10s 421ms/step - loss: 0.0700 - accuracy: 0.9761 - val_loss: 1.9915 - val_accuracy: 0.7400\n",
      "Epoch 587/700\n",
      "23/23 [==============================] - 10s 434ms/step - loss: 0.0631 - accuracy: 0.9770 - val_loss: 1.9553 - val_accuracy: 0.7479\n",
      "Epoch 588/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0640 - accuracy: 0.9768 - val_loss: 1.9641 - val_accuracy: 0.7447\n",
      "Epoch 589/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0613 - accuracy: 0.9772 - val_loss: 2.0457 - val_accuracy: 0.7416\n",
      "Epoch 590/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0637 - accuracy: 0.9775 - val_loss: 1.9353 - val_accuracy: 0.7463\n",
      "Epoch 591/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0667 - accuracy: 0.9775 - val_loss: 1.9461 - val_accuracy: 0.7421\n",
      "Epoch 592/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0607 - accuracy: 0.9779 - val_loss: 1.9707 - val_accuracy: 0.7453\n",
      "Epoch 593/700\n",
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0607 - accuracy: 0.9783 - val_loss: 1.9360 - val_accuracy: 0.7521\n",
      "Epoch 594/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0580 - accuracy: 0.9786 - val_loss: 1.9541 - val_accuracy: 0.7458\n",
      "Epoch 595/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0565 - accuracy: 0.9791 - val_loss: 1.9400 - val_accuracy: 0.7526\n",
      "Epoch 596/700\n",
      "23/23 [==============================] - 8s 339ms/step - loss: 0.0599 - accuracy: 0.9791 - val_loss: 1.9917 - val_accuracy: 0.7489\n",
      "Epoch 597/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0563 - accuracy: 0.9796 - val_loss: 1.9652 - val_accuracy: 0.7547\n",
      "Epoch 598/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0596 - accuracy: 0.9787 - val_loss: 1.9524 - val_accuracy: 0.7363\n",
      "Epoch 599/700\n",
      "23/23 [==============================] - 8s 335ms/step - loss: 0.0594 - accuracy: 0.9799 - val_loss: 1.9653 - val_accuracy: 0.7495\n",
      "Epoch 600/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0550 - accuracy: 0.9808 - val_loss: 1.9823 - val_accuracy: 0.7516\n",
      "Epoch 601/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0560 - accuracy: 0.9798 - val_loss: 2.0091 - val_accuracy: 0.7453\n",
      "Epoch 602/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0691 - accuracy: 0.9772 - val_loss: 1.9752 - val_accuracy: 0.7395\n",
      "Epoch 603/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0549 - accuracy: 0.9816 - val_loss: 1.8890 - val_accuracy: 0.7495\n",
      "Epoch 604/700\n",
      "23/23 [==============================] - 8s 336ms/step - loss: 0.0526 - accuracy: 0.9811 - val_loss: 1.9222 - val_accuracy: 0.7547\n",
      "Epoch 605/700\n",
      "23/23 [==============================] - 9s 380ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 1.9354 - val_accuracy: 0.7489\n",
      "Epoch 606/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0525 - accuracy: 0.9796 - val_loss: 1.8529 - val_accuracy: 0.7542\n",
      "Epoch 607/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 1.8812 - val_accuracy: 0.7521\n",
      "Epoch 608/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0521 - accuracy: 0.9800 - val_loss: 1.8949 - val_accuracy: 0.7579\n",
      "Epoch 609/700\n",
      "23/23 [==============================] - 10s 421ms/step - loss: 0.0495 - accuracy: 0.9806 - val_loss: 1.8795 - val_accuracy: 0.7605\n",
      "Epoch 610/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0521 - accuracy: 0.9808 - val_loss: 1.9098 - val_accuracy: 0.7526\n",
      "Epoch 611/700\n",
      "23/23 [==============================] - 9s 392ms/step - loss: 0.0498 - accuracy: 0.9810 - val_loss: 1.9356 - val_accuracy: 0.7511\n",
      "Epoch 612/700\n",
      "23/23 [==============================] - 9s 406ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 1.8966 - val_accuracy: 0.7568\n",
      "Epoch 613/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0492 - accuracy: 0.9807 - val_loss: 1.8871 - val_accuracy: 0.7495\n",
      "Epoch 614/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0497 - accuracy: 0.9803 - val_loss: 1.9530 - val_accuracy: 0.7468\n",
      "Epoch 615/700\n",
      "23/23 [==============================] - 8s 367ms/step - loss: 0.0465 - accuracy: 0.9823 - val_loss: 1.8931 - val_accuracy: 0.7542\n",
      "Epoch 616/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0506 - accuracy: 0.9810 - val_loss: 1.8885 - val_accuracy: 0.7547\n",
      "Epoch 617/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0580 - accuracy: 0.9790 - val_loss: 1.8578 - val_accuracy: 0.7610\n",
      "Epoch 618/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0536 - accuracy: 0.9793 - val_loss: 1.9032 - val_accuracy: 0.7595\n",
      "Epoch 619/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 359ms/step - loss: 0.0506 - accuracy: 0.9802 - val_loss: 1.8741 - val_accuracy: 0.7610\n",
      "Epoch 620/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0484 - accuracy: 0.9807 - val_loss: 1.9167 - val_accuracy: 0.7563\n",
      "Epoch 621/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0487 - accuracy: 0.9815 - val_loss: 1.9421 - val_accuracy: 0.7547\n",
      "Epoch 622/700\n",
      "23/23 [==============================] - 8s 358ms/step - loss: 0.0492 - accuracy: 0.9803 - val_loss: 1.9174 - val_accuracy: 0.7516\n",
      "Epoch 623/700\n",
      "23/23 [==============================] - 8s 337ms/step - loss: 0.0464 - accuracy: 0.9812 - val_loss: 1.9443 - val_accuracy: 0.7547\n",
      "Epoch 624/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0481 - accuracy: 0.9820 - val_loss: 1.9510 - val_accuracy: 0.7547\n",
      "Epoch 625/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 1.9649 - val_accuracy: 0.7468\n",
      "Epoch 626/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0463 - accuracy: 0.9817 - val_loss: 1.9922 - val_accuracy: 0.7532\n",
      "Epoch 627/700\n",
      "23/23 [==============================] - 9s 400ms/step - loss: 0.0467 - accuracy: 0.9825 - val_loss: 1.9687 - val_accuracy: 0.7521\n",
      "Epoch 628/700\n",
      "23/23 [==============================] - 8s 340ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 1.9760 - val_accuracy: 0.7479\n",
      "Epoch 629/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0452 - accuracy: 0.9823 - val_loss: 1.9368 - val_accuracy: 0.7610\n",
      "Epoch 630/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0455 - accuracy: 0.9825 - val_loss: 1.9629 - val_accuracy: 0.7553\n",
      "Epoch 631/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0479 - accuracy: 0.9827 - val_loss: 1.9468 - val_accuracy: 0.7553\n",
      "Epoch 632/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0464 - accuracy: 0.9817 - val_loss: 1.9733 - val_accuracy: 0.7526\n",
      "Epoch 633/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0440 - accuracy: 0.9827 - val_loss: 1.8966 - val_accuracy: 0.7626\n",
      "Epoch 634/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0458 - accuracy: 0.9810 - val_loss: 1.9804 - val_accuracy: 0.7605\n",
      "Epoch 635/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0437 - accuracy: 0.9823 - val_loss: 1.9711 - val_accuracy: 0.7484\n",
      "Epoch 636/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0441 - accuracy: 0.9832 - val_loss: 1.9667 - val_accuracy: 0.7563\n",
      "Epoch 637/700\n",
      "23/23 [==============================] - 8s 356ms/step - loss: 0.0452 - accuracy: 0.9824 - val_loss: 1.9717 - val_accuracy: 0.7479\n",
      "Epoch 638/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0506 - accuracy: 0.9814 - val_loss: 1.9271 - val_accuracy: 0.7547\n",
      "Epoch 639/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0450 - accuracy: 0.9825 - val_loss: 1.9272 - val_accuracy: 0.7553\n",
      "Epoch 640/700\n",
      "23/23 [==============================] - 9s 375ms/step - loss: 0.0452 - accuracy: 0.9835 - val_loss: 1.9867 - val_accuracy: 0.7568\n",
      "Epoch 641/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0506 - accuracy: 0.9817 - val_loss: 1.9395 - val_accuracy: 0.7584\n",
      "Epoch 642/700\n",
      "23/23 [==============================] - 8s 345ms/step - loss: 0.0503 - accuracy: 0.9812 - val_loss: 1.9588 - val_accuracy: 0.7553\n",
      "Epoch 643/700\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0464 - accuracy: 0.9832 - val_loss: 2.0294 - val_accuracy: 0.7521\n",
      "Epoch 644/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0423 - accuracy: 0.9831 - val_loss: 2.0232 - val_accuracy: 0.7495\n",
      "Epoch 645/700\n",
      "23/23 [==============================] - 8s 338ms/step - loss: 0.0439 - accuracy: 0.9831 - val_loss: 2.0366 - val_accuracy: 0.7547\n",
      "Epoch 646/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0509 - accuracy: 0.9821 - val_loss: 2.0109 - val_accuracy: 0.7516\n",
      "Epoch 647/700\n",
      "23/23 [==============================] - 8s 336ms/step - loss: 0.0501 - accuracy: 0.9820 - val_loss: 2.0419 - val_accuracy: 0.7468\n",
      "Epoch 648/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0519 - accuracy: 0.9810 - val_loss: 2.0506 - val_accuracy: 0.7595\n",
      "Epoch 649/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0472 - accuracy: 0.9823 - val_loss: 2.0166 - val_accuracy: 0.7574\n",
      "Epoch 650/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0462 - accuracy: 0.9820 - val_loss: 2.0113 - val_accuracy: 0.7563\n",
      "Epoch 651/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0466 - accuracy: 0.9831 - val_loss: 2.0732 - val_accuracy: 0.7474\n",
      "Epoch 652/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0436 - accuracy: 0.9823 - val_loss: 2.0412 - val_accuracy: 0.7521\n",
      "Epoch 653/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0444 - accuracy: 0.9827 - val_loss: 2.0305 - val_accuracy: 0.7511\n",
      "Epoch 654/700\n",
      "23/23 [==============================] - 8s 346ms/step - loss: 0.0464 - accuracy: 0.9828 - val_loss: 1.9870 - val_accuracy: 0.7558\n",
      "Epoch 655/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0467 - accuracy: 0.9816 - val_loss: 1.9629 - val_accuracy: 0.7505\n",
      "Epoch 656/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0465 - accuracy: 0.9825 - val_loss: 1.9318 - val_accuracy: 0.7563\n",
      "Epoch 657/700\n",
      "23/23 [==============================] - 8s 342ms/step - loss: 0.0438 - accuracy: 0.9836 - val_loss: 2.0124 - val_accuracy: 0.7489\n",
      "Epoch 658/700\n",
      "23/23 [==============================] - 9s 384ms/step - loss: 0.0446 - accuracy: 0.9819 - val_loss: 2.0724 - val_accuracy: 0.7468\n",
      "Epoch 659/700\n",
      "23/23 [==============================] - 9s 372ms/step - loss: 0.0457 - accuracy: 0.9824 - val_loss: 2.0856 - val_accuracy: 0.7421\n",
      "Epoch 660/700\n",
      "23/23 [==============================] - 8s 366ms/step - loss: 0.0418 - accuracy: 0.9825 - val_loss: 2.0311 - val_accuracy: 0.7447\n",
      "Epoch 661/700\n",
      "23/23 [==============================] - 8s 353ms/step - loss: 0.0432 - accuracy: 0.9828 - val_loss: 2.0144 - val_accuracy: 0.7484\n",
      "Epoch 662/700\n",
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0431 - accuracy: 0.9828 - val_loss: 2.0476 - val_accuracy: 0.7495\n",
      "Epoch 663/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0420 - accuracy: 0.9835 - val_loss: 2.0509 - val_accuracy: 0.7463\n",
      "Epoch 664/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0463 - accuracy: 0.9828 - val_loss: 2.0849 - val_accuracy: 0.7489\n",
      "Epoch 665/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0451 - accuracy: 0.9823 - val_loss: 2.0613 - val_accuracy: 0.7521\n",
      "Epoch 666/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0456 - accuracy: 0.9823 - val_loss: 2.1647 - val_accuracy: 0.7405\n",
      "Epoch 667/700\n",
      "23/23 [==============================] - 8s 370ms/step - loss: 0.0504 - accuracy: 0.9816 - val_loss: 2.1127 - val_accuracy: 0.7311\n",
      "Epoch 668/700\n",
      "23/23 [==============================] - 8s 351ms/step - loss: 0.0492 - accuracy: 0.9820 - val_loss: 2.0584 - val_accuracy: 0.7453\n",
      "Epoch 669/700\n",
      "23/23 [==============================] - 8s 350ms/step - loss: 0.0445 - accuracy: 0.9832 - val_loss: 2.1271 - val_accuracy: 0.7384\n",
      "Epoch 670/700\n",
      "23/23 [==============================] - 9s 377ms/step - loss: 0.0443 - accuracy: 0.9841 - val_loss: 2.1177 - val_accuracy: 0.7437\n",
      "Epoch 671/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0440 - accuracy: 0.9831 - val_loss: 2.0715 - val_accuracy: 0.7511\n",
      "Epoch 672/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0440 - accuracy: 0.9825 - val_loss: 2.1106 - val_accuracy: 0.7484\n",
      "Epoch 673/700\n",
      "23/23 [==============================] - 8s 347ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 2.1004 - val_accuracy: 0.7495\n",
      "Epoch 674/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0420 - accuracy: 0.9832 - val_loss: 2.1279 - val_accuracy: 0.7458\n",
      "Epoch 675/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 8s 344ms/step - loss: 0.0425 - accuracy: 0.9838 - val_loss: 2.0781 - val_accuracy: 0.7453\n",
      "Epoch 676/700\n",
      "23/23 [==============================] - 8s 348ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 2.1183 - val_accuracy: 0.7437\n",
      "Epoch 677/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0450 - accuracy: 0.9833 - val_loss: 2.1055 - val_accuracy: 0.7474\n",
      "Epoch 678/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0441 - accuracy: 0.9835 - val_loss: 2.1512 - val_accuracy: 0.7395\n",
      "Epoch 679/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0445 - accuracy: 0.9833 - val_loss: 2.1353 - val_accuracy: 0.7458\n",
      "Epoch 680/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 2.1624 - val_accuracy: 0.7421\n",
      "Epoch 681/700\n",
      "23/23 [==============================] - 8s 341ms/step - loss: 0.0471 - accuracy: 0.9827 - val_loss: 2.1417 - val_accuracy: 0.7405\n",
      "Epoch 682/700\n",
      "23/23 [==============================] - 8s 361ms/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 2.1089 - val_accuracy: 0.7516\n",
      "Epoch 683/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0424 - accuracy: 0.9840 - val_loss: 2.1660 - val_accuracy: 0.7442\n",
      "Epoch 684/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0425 - accuracy: 0.9844 - val_loss: 2.1454 - val_accuracy: 0.7437\n",
      "Epoch 685/700\n",
      "23/23 [==============================] - 8s 336ms/step - loss: 0.0433 - accuracy: 0.9831 - val_loss: 2.1482 - val_accuracy: 0.7390\n",
      "Epoch 686/700\n",
      "23/23 [==============================] - 8s 369ms/step - loss: 0.0421 - accuracy: 0.9831 - val_loss: 2.1866 - val_accuracy: 0.7437\n",
      "Epoch 687/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0423 - accuracy: 0.9842 - val_loss: 2.1674 - val_accuracy: 0.7421\n",
      "Epoch 688/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0419 - accuracy: 0.9837 - val_loss: 2.1970 - val_accuracy: 0.7432\n",
      "Epoch 689/700\n",
      "23/23 [==============================] - 8s 363ms/step - loss: 0.0416 - accuracy: 0.9836 - val_loss: 2.1776 - val_accuracy: 0.7505\n",
      "Epoch 690/700\n",
      "23/23 [==============================] - 8s 360ms/step - loss: 0.0430 - accuracy: 0.9841 - val_loss: 2.1492 - val_accuracy: 0.7458\n",
      "Epoch 691/700\n",
      "23/23 [==============================] - 8s 362ms/step - loss: 0.0425 - accuracy: 0.9836 - val_loss: 2.1703 - val_accuracy: 0.7421\n",
      "Epoch 692/700\n",
      "23/23 [==============================] - 8s 354ms/step - loss: 0.0413 - accuracy: 0.9840 - val_loss: 2.1598 - val_accuracy: 0.7437\n",
      "Epoch 693/700\n",
      "23/23 [==============================] - 8s 357ms/step - loss: 0.0409 - accuracy: 0.9831 - val_loss: 2.1597 - val_accuracy: 0.7474\n",
      "Epoch 694/700\n",
      "23/23 [==============================] - 8s 352ms/step - loss: 0.0431 - accuracy: 0.9829 - val_loss: 2.1854 - val_accuracy: 0.7395\n",
      "Epoch 695/700\n",
      "23/23 [==============================] - 8s 368ms/step - loss: 0.0422 - accuracy: 0.9844 - val_loss: 2.1930 - val_accuracy: 0.7395\n",
      "Epoch 696/700\n",
      "23/23 [==============================] - 8s 365ms/step - loss: 0.0402 - accuracy: 0.9838 - val_loss: 2.1632 - val_accuracy: 0.7500\n",
      "Epoch 697/700\n",
      "23/23 [==============================] - 8s 343ms/step - loss: 0.0401 - accuracy: 0.9846 - val_loss: 2.2035 - val_accuracy: 0.7384\n",
      "Epoch 698/700\n",
      "23/23 [==============================] - 8s 349ms/step - loss: 0.0408 - accuracy: 0.9841 - val_loss: 2.2014 - val_accuracy: 0.7384\n",
      "Epoch 699/700\n",
      "23/23 [==============================] - 8s 355ms/step - loss: 0.0408 - accuracy: 0.9853 - val_loss: 2.2044 - val_accuracy: 0.7374\n",
      "Epoch 700/700\n",
      "23/23 [==============================] - 9s 371ms/step - loss: 0.0390 - accuracy: 0.9850 - val_loss: 2.1893 - val_accuracy: 0.7374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_28_layer_call_fn, lstm_cell_28_layer_call_and_return_conditional_losses, lstm_cell_29_layer_call_fn, lstm_cell_29_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fda14b13ac0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fda18b78130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "571af464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "# Restore the model and construct the encoder and decoder.\n",
    "model = keras.models.load_model(\"s2s\")\n",
    "\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2cb62d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Abbotsford Regional Hospital and Cancer Centre Fraser Health Authority Suite 400 Central City Tower 13450 - 102 Avenue Surrey BC  V3T 0H1\n",
      "Decoded sentence: South Okanagan General Hospital\n",
      "\n",
      "-\n",
      "Input sentence: Abbotsford Regional Hospital and Cancer Centre Fraser Health Authority Suite 400 Central City Tower 13450 - 102 Avenue Surrey BC  V3T 0H1\n",
      "Decoded sentence: South Okanagan General Hospital\n",
      "\n",
      "-\n",
      "Input sentence: Cormorant Island Community Health Centre Vancouver Island Health Authority 1952 Bay Street Victoria, BC, V8R 1J8\n",
      "Decoded sentence: St. John Hospital\n",
      "\n",
      "-\n",
      "Input sentence: Cormorant Island Community Health Centre Vancouver Island Health Authority 1952 Bay Street Victoria, BC, V8R 1J8\n",
      "Decoded sentence: St. John Hospital\n",
      "\n",
      "-\n",
      "Input sentence: Ashcroft and District General Hospital Interior Health Authority Community Health and Services Centre 5th Floor 505 Doyle Avenue Kelowna, BC, V1Y 6V8\n",
      "Decoded sentence: St. Paul's Hospital\n",
      "\n",
      "-\n",
      "Input sentence: Ashcroft and District General Hospital Interior Health Authority Community Health and Services Centre 5th Floor 505 Doyle Avenue Kelowna, BC, V1Y 6V8\n",
      "Decoded sentence: St. Paul's Hospital\n",
      "\n",
      "-\n",
      "Input sentence: R.W. Large Memorial Hospital Vancouver Coastal Health Authority 11th Floor  601 W. Broadway Vancouver BC  V6Z 1Y6\n",
      "Decoded sentence: Peace Lutheran Extended Care Centre\n",
      "\n",
      "-\n",
      "Input sentence: R.W. Large Memorial Hospital Vancouver Coastal Health Authority 11th Floor  601 W. Broadway Vancouver BC  V6Z 1Y6\n",
      "Decoded sentence: Peace Lutheran Extended Care Centre\n",
      "\n",
      "-\n",
      "Input sentence: Bella Coola General Hospital Vancouver Coastal Health Authority 11th Floor  601 W. Broadway Vancouver BC  V6Z 1Y6\n",
      "Decoded sentence: Peace Arch District Hospital\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jb/3yk35v0d3d7394m63986s12r0000gn/T/ipykernel_8632/242227767.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input sentence:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jb/3yk35v0d3d7394m63986s12r0000gn/T/ipykernel_8632/629287628.py\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Sample a token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1949\u001b[0m               stacklevel=2)\n\u001b[1;32m   1950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1952\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    358\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     dataset = dataset.map(\n\u001b[0m\u001b[1;32m    361\u001b[0m         grab_batch, num_parallel_calls=tf.data.AUTOTUNE)\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2016\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2018\u001b[0;31m       return ParallelMapDataset(\n\u001b[0m\u001b[1;32m   2019\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m           \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5232\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5233\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5234\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   5235\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3068\u001b[0m          \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3069\u001b[0m     \"\"\"\n\u001b[0;32m-> 3070\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   3071\u001b[0m         *args, **kwargs)\n\u001b[1;32m   3072\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3128\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1073\u001b[0m       \u001b[0marg_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m       \u001b[0mkwarg_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m     func_args = _get_defun_inputs_from_args(\n\u001b[0m\u001b[1;32m   1076\u001b[0m         args, arg_names, flat_shapes=arg_shapes)\n\u001b[1;32m   1077\u001b[0m     func_kwargs = _get_defun_inputs_from_kwargs(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs_from_args\u001b[0;34m(args, names, flat_shapes)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_defun_inputs_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m   \u001b[0;34m\"\"\"Maps Python function positional args to graph-construction inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m   return _get_defun_inputs(\n\u001b[0m\u001b[1;32m   1314\u001b[0m       args, names, structure=args, flat_shapes=flat_shapes)\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs\u001b[0;34m(args, names, structure, flat_shapes)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mplaceholder_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m           placeholder = graph_placeholder(\n\u001b[0m\u001b[1;32m   1387\u001b[0m               \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               name=requested_name)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       attrs=attrs, name=name)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    691\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3774\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3775\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3776\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3777\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3778\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2169\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2172\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2173\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for seq_index in range(50):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)\n",
    "    \n",
    "    \n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5afd7d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "89659350",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = \"North York General Hospital Fraser Health Authority, 194 King Street East Toronto ON V1K 4H5\"\n",
    "\n",
    "new_encoder_input_data = np.zeros(\n",
    "    (1,max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for t, char in enumerate(new_input):\n",
    "    new_encoder_input_data[0,t, input_token_index[char]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5e170e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Port McNeill and District Hospital\\n'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(new_encoder_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2cffea90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
